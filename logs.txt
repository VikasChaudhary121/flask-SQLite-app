* 
* ==> Audit <==
* |------------|-----------------------|----------|----------|---------|---------------------|---------------------|
|  Command   |         Args          | Profile  |   User   | Version |     Start Time      |      End Time       |
|------------|-----------------------|----------|----------|---------|---------------------|---------------------|
| start      |                       | minikube | vikas121 | v1.32.0 | 12 Jan 24 22:17 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 12 Jan 24 22:18 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 12 Jan 24 22:33 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 13 Jan 24 11:21 IST |                     |
| kubectl    | -- get po -A          | minikube | vikas121 | v1.32.0 | 13 Jan 24 11:52 IST |                     |
| delete     |                       | minikube | vikas121 | v1.32.0 | 13 Jan 24 12:03 IST | 13 Jan 24 12:03 IST |
| start      | --wait=10m            | minikube | vikas121 | v1.32.0 | 13 Jan 24 12:03 IST |                     |
| start      | --driver=virtualbox   | minikube | vikas121 | v1.32.0 | 13 Jan 24 12:04 IST |                     |
| start      | --wait=10m            | minikube | vikas121 | v1.32.0 | 13 Jan 24 12:04 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 13 Jan 24 12:18 IST |                     |
| delete     | --all                 | minikube | vikas121 | v1.32.0 | 13 Jan 24 12:19 IST | 13 Jan 24 12:19 IST |
| start      | --driver=virtualbox   | minikube | vikas121 | v1.32.0 | 13 Jan 24 12:34 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 19 Jan 24 19:41 IST | 19 Jan 24 19:56 IST |
| dashboard  |                       | minikube | vikas121 | v1.32.0 | 19 Jan 24 20:01 IST |                     |
| ssh        |                       | minikube | vikas121 | v1.32.0 | 19 Jan 24 20:17 IST | 19 Jan 24 20:18 IST |
| ssh        |                       | minikube | vikas121 | v1.32.0 | 19 Jan 24 20:19 IST | 19 Jan 24 20:19 IST |
| ssh        |                       | minikube | vikas121 | v1.32.0 | 20 Jan 24 00:48 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 20 Jan 24 10:30 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 20 Jan 24 12:09 IST | 20 Jan 24 12:21 IST |
| start      |                       | minikube | vikas121 | v1.32.0 | 20 Jan 24 15:45 IST | 20 Jan 24 15:58 IST |
| addons     | enable metrics-server | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:03 IST | 20 Jan 24 16:03 IST |
| addons     | enable metrics-server | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:03 IST | 20 Jan 24 16:03 IST |
| start      |                       | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:09 IST | 20 Jan 24 16:12 IST |
| addons     | enable metrics-server | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:14 IST | 20 Jan 24 16:14 IST |
| start      |                       | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:18 IST | 20 Jan 24 16:20 IST |
| docker-env | minikube docker-env   | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:30 IST | 20 Jan 24 16:30 IST |
| docker-env | minikube docker-env   | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:32 IST | 20 Jan 24 16:32 IST |
| docker-env | minikube docker-env   | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:32 IST | 20 Jan 24 16:32 IST |
| start      |                       | minikube | vikas121 | v1.32.0 | 20 Jan 24 16:42 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 23 Jan 24 00:27 IST | 23 Jan 24 00:38 IST |
| start      |                       | minikube | vikas121 | v1.32.0 | 23 Jan 24 18:44 IST | 23 Jan 24 18:54 IST |
| ip         |                       | minikube | vikas121 | v1.32.0 | 23 Jan 24 19:22 IST | 23 Jan 24 19:22 IST |
| ip         |                       | minikube | vikas121 | v1.32.0 | 23 Jan 24 19:30 IST | 23 Jan 24 19:30 IST |
| ip         |                       | minikube | vikas121 | v1.32.0 | 23 Jan 24 19:45 IST | 23 Jan 24 19:45 IST |
| start      |                       | minikube | vikas121 | v1.32.0 | 23 Jan 24 23:43 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 23 Jan 24 23:48 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 23 Jan 24 23:51 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 24 Jan 24 16:55 IST | 24 Jan 24 17:02 IST |
| start      |                       | minikube | vikas121 | v1.32.0 | 24 Jan 24 19:11 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 30 Jan 24 19:39 IST |                     |
| start      |                       | minikube | vikas121 | v1.32.0 | 31 Jan 24 13:24 IST | 31 Jan 24 13:32 IST |
| addons     | enable metrics-server | minikube | vikas121 | v1.32.0 | 31 Jan 24 14:05 IST |                     |
|------------|-----------------------|----------|----------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2024/01/31 13:24:19
Running on machine: vikas121
Binary: Built with gc go1.21.3 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0131 13:24:19.455478    5462 out.go:296] Setting OutFile to fd 1 ...
I0131 13:24:19.456175    5462 out.go:348] isatty.IsTerminal(1) = true
I0131 13:24:19.456194    5462 out.go:309] Setting ErrFile to fd 2...
I0131 13:24:19.456228    5462 out.go:348] isatty.IsTerminal(2) = true
I0131 13:24:19.457890    5462 root.go:338] Updating PATH: /home/vikas121/.minikube/bin
I0131 13:24:19.536699    5462 out.go:303] Setting JSON to false
I0131 13:24:19.591773    5462 start.go:128] hostinfo: {"hostname":"vikas121","uptime":486,"bootTime":1706687173,"procs":243,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"22.04","kernelVersion":"6.5.0-15-generic","kernelArch":"x86_64","virtualizationSystem":"kvm","virtualizationRole":"host","hostId":"3c45da2e-fc03-4063-b8a9-bb090643bbc0"}
I0131 13:24:19.592125    5462 start.go:138] virtualization: kvm host
I0131 13:24:19.661092    5462 out.go:177] 😄  minikube v1.32.0 on Ubuntu 22.04
I0131 13:24:19.802776    5462 notify.go:220] Checking for updates...
I0131 13:24:19.857739    5462 config.go:182] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0131 13:24:19.858206    5462 driver.go:378] Setting default libvirt URI to qemu:///system
I0131 13:24:20.049642    5462 out.go:177] ✨  Using the qemu2 driver based on existing profile
I0131 13:24:20.108854    5462 start.go:298] selected driver: qemu2
I0131 13:24:20.109513    5462 start.go:902] validating driver "qemu2" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.32.1-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:37987 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:builtin Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/vikas121:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0131 13:24:20.109882    5462 start.go:913] status for qemu2: {Installed:true Healthy:true Running:true NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0131 13:24:20.112832    5462 cni.go:84] Creating CNI manager for ""
I0131 13:24:20.112901    5462 cni.go:158] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0131 13:24:20.112944    5462 start_flags.go:323] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.32.1-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:37987 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:builtin Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/vikas121:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0131 13:24:20.144017    5462 iso.go:125] acquiring lock: {Name:mk8d8c4721b4763c0a1070553590e452f61df14c Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0131 13:24:20.217227    5462 out.go:177] 👍  Starting control plane node minikube in cluster minikube
I0131 13:24:20.296836    5462 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0131 13:24:20.296987    5462 preload.go:148] Found local preload: /home/vikas121/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.28.3-docker-overlay2-amd64.tar.lz4
I0131 13:24:20.297003    5462 cache.go:56] Caching tarball of preloaded images
I0131 13:24:20.297373    5462 preload.go:174] Found /home/vikas121/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.28.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0131 13:24:20.297393    5462 cache.go:59] Finished verifying existence of preloaded tar for  v1.28.3 on docker
I0131 13:24:20.297574    5462 profile.go:148] Saving config to /home/vikas121/.minikube/profiles/minikube/config.json ...
I0131 13:24:20.298072    5462 start.go:365] acquiring machines lock for minikube: {Name:mk9e5c7439873ca119c8c50988815e170af446a6 Clock:{} Delay:500ms Timeout:13m0s Cancel:<nil>}
I0131 13:24:20.298233    5462 start.go:369] acquired machines lock for "minikube" in 130.808µs
I0131 13:24:20.298262    5462 start.go:96] Skipping create...Using existing machine configuration
I0131 13:24:20.298317    5462 fix.go:54] fixHost starting: 
I0131 13:24:20.313345    5462 fix.go:102] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0131 13:24:20.313399    5462 fix.go:128] unexpected machine state, will restart: <nil>
I0131 13:24:20.384938    5462 out.go:177] 🔄  Restarting existing qemu2 VM for "minikube" ...
I0131 13:24:20.463460    5462 main.go:141] libmachine: executing: qemu-system-x86_64 -cpu max -display none -accel kvm -m 2200 -smp 2 -boot d -cdrom /home/vikas121/.minikube/machines/minikube/boot2docker.iso -qmp unix:/home/vikas121/.minikube/machines/minikube/monitor,server,nowait -pidfile /home/vikas121/.minikube/machines/minikube/qemu.pid -nic user,model=virtio,hostfwd=tcp::33481-:22,hostfwd=tcp::38299-:2376,hostname=minikube -daemonize /home/vikas121/.minikube/machines/minikube/disk.qcow2
I0131 13:24:21.554257    5462 main.go:141] libmachine: STDOUT: 
I0131 13:24:21.554287    5462 main.go:141] libmachine: STDERR: 
I0131 13:24:21.554312    5462 main.go:141] libmachine: Waiting for VM to start (ssh -p 33481 docker@127.0.0.1)...
W0131 13:24:31.746845    5462 notify.go:59] Error getting json from minikube version url: error with http GET for endpoint https://storage.googleapis.com/minikube/releases-v2.json: Get "https://storage.googleapis.com/minikube/releases-v2.json": net/http: TLS handshake timeout
I0131 13:25:48.198377    5462 profile.go:148] Saving config to /home/vikas121/.minikube/profiles/minikube/config.json ...
I0131 13:25:48.503111    5462 machine.go:88] provisioning docker machine ...
I0131 13:25:49.143490    5462 buildroot.go:166] provisioning hostname "minikube"
I0131 13:25:50.296776    5462 main.go:141] libmachine: Using SSH client type: native
I0131 13:25:52.038333    5462 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} localhost 33481 <nil> <nil>}
I0131 13:25:52.038397    5462 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0131 13:25:54.558491    5462 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0131 13:25:54.690251    5462 main.go:141] libmachine: Using SSH client type: native
I0131 13:25:54.692116    5462 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} localhost 33481 <nil> <nil>}
I0131 13:25:54.692191    5462 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0131 13:25:55.407690    5462 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0131 13:25:55.464848    5462 buildroot.go:172] set auth options {CertDir:/home/vikas121/.minikube CaCertPath:/home/vikas121/.minikube/certs/ca.pem CaPrivateKeyPath:/home/vikas121/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/vikas121/.minikube/machines/server.pem ServerKeyPath:/home/vikas121/.minikube/machines/server-key.pem ClientKeyPath:/home/vikas121/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/vikas121/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/vikas121/.minikube}
I0131 13:25:55.464932    5462 buildroot.go:174] setting up certificates
I0131 13:25:55.484458    5462 provision.go:83] configureAuth start
I0131 13:25:55.484499    5462 provision.go:138] copyHostCerts
I0131 13:25:55.653163    5462 exec_runner.go:144] found /home/vikas121/.minikube/ca.pem, removing ...
I0131 13:25:55.653228    5462 exec_runner.go:203] rm: /home/vikas121/.minikube/ca.pem
I0131 13:25:55.653541    5462 exec_runner.go:151] cp: /home/vikas121/.minikube/certs/ca.pem --> /home/vikas121/.minikube/ca.pem (1082 bytes)
I0131 13:25:55.724323    5462 exec_runner.go:144] found /home/vikas121/.minikube/cert.pem, removing ...
I0131 13:25:55.724365    5462 exec_runner.go:203] rm: /home/vikas121/.minikube/cert.pem
I0131 13:25:55.724580    5462 exec_runner.go:151] cp: /home/vikas121/.minikube/certs/cert.pem --> /home/vikas121/.minikube/cert.pem (1127 bytes)
I0131 13:25:55.795092    5462 exec_runner.go:144] found /home/vikas121/.minikube/key.pem, removing ...
I0131 13:25:55.795133    5462 exec_runner.go:203] rm: /home/vikas121/.minikube/key.pem
I0131 13:25:55.795352    5462 exec_runner.go:151] cp: /home/vikas121/.minikube/certs/key.pem --> /home/vikas121/.minikube/key.pem (1679 bytes)
I0131 13:25:55.796015    5462 provision.go:112] generating server cert: /home/vikas121/.minikube/machines/server.pem ca-key=/home/vikas121/.minikube/certs/ca.pem private-key=/home/vikas121/.minikube/certs/ca-key.pem org=vikas121.minikube san=[127.0.0.1 localhost localhost 127.0.0.1 minikube minikube]
I0131 13:25:57.164966    5462 provision.go:172] copyRemoteCerts
I0131 13:25:57.191492    5462 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0131 13:25:57.192000    5462 sshutil.go:53] new ssh client: &{IP:localhost Port:33481 SSHKeyPath:/home/vikas121/.minikube/machines/minikube/id_rsa Username:docker}
I0131 13:25:57.465276    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0131 13:25:57.516647    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/machines/server.pem --> /etc/docker/server.pem (1212 bytes)
I0131 13:25:57.586086    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1679 bytes)
I0131 13:25:57.637461    5462 provision.go:86] duration metric: configureAuth took 2.152964163s
I0131 13:25:57.637494    5462 buildroot.go:189] setting minikube options for container-runtime
I0131 13:25:57.656546    5462 config.go:182] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0131 13:25:57.659188    5462 main.go:141] libmachine: Using SSH client type: native
I0131 13:25:57.699712    5462 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} localhost 33481 <nil> <nil>}
I0131 13:25:57.699788    5462 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0131 13:25:58.092344    5462 main.go:141] libmachine: SSH cmd err, output: <nil>: tmpfs

I0131 13:25:58.092372    5462 buildroot.go:70] root file system type: tmpfs
I0131 13:25:58.176631    5462 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0131 13:25:58.176772    5462 main.go:141] libmachine: Using SSH client type: native
I0131 13:25:58.177627    5462 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} localhost 33481 <nil> <nil>}
I0131 13:25:58.177809    5462 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=qemu2 --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0131 13:25:58.497746    5462 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=qemu2 --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0131 13:25:58.858123    5462 main.go:141] libmachine: Using SSH client type: native
I0131 13:25:58.918582    5462 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} localhost 33481 <nil> <nil>}
I0131 13:25:58.918682    5462 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0131 13:26:43.169053    5462 main.go:141] libmachine: SSH cmd err, output: <nil>: diff: can't stat '/lib/systemd/system/docker.service': No such file or directory
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /usr/lib/systemd/system/docker.service.

I0131 13:26:43.169101    5462 machine.go:91] provisioned docker machine in 54.635557395s
I0131 13:26:43.176529    5462 start.go:300] post-start starting for "minikube" (driver="qemu2")
I0131 13:26:43.176809    5462 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0131 13:26:43.202053    5462 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0131 13:26:43.202113    5462 sshutil.go:53] new ssh client: &{IP:localhost Port:33481 SSHKeyPath:/home/vikas121/.minikube/machines/minikube/id_rsa Username:docker}
I0131 13:26:43.545700    5462 ssh_runner.go:195] Run: cat /etc/os-release
I0131 13:26:43.565017    5462 info.go:137] Remote host: Buildroot 2021.02.12
I0131 13:26:43.565070    5462 filesync.go:126] Scanning /home/vikas121/.minikube/addons for local assets ...
I0131 13:26:43.620000    5462 filesync.go:126] Scanning /home/vikas121/.minikube/files for local assets ...
I0131 13:26:43.620657    5462 start.go:303] post-start completed in 444.097813ms
I0131 13:26:43.620686    5462 fix.go:56] fixHost completed within 2m23.322409036s
I0131 13:26:43.620873    5462 main.go:141] libmachine: Using SSH client type: native
I0131 13:26:43.622699    5462 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x808a40] 0x80b720 <nil>  [] 0s} localhost 33481 <nil> <nil>}
I0131 13:26:43.622735    5462 main.go:141] libmachine: About to run SSH command:
date +%!s(MISSING).%!N(MISSING)
I0131 13:26:43.895000    5462 main.go:141] libmachine: SSH cmd err, output: <nil>: 1706687803.866194649

I0131 13:26:43.895025    5462 fix.go:206] guest clock: 1706687803.866194649
I0131 13:26:43.895046    5462 fix.go:219] Guest: 2024-01-31 13:26:43.866194649 +0530 IST Remote: 2024-01-31 13:26:43.620703463 +0530 IST m=+148.027444162 (delta=245.491186ms)
I0131 13:26:43.908657    5462 fix.go:190] guest clock delta is within tolerance: 245.491186ms
I0131 13:26:43.908683    5462 start.go:83] releasing machines lock for "minikube", held for 2m23.610428408s
I0131 13:26:43.993682    5462 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0131 13:26:43.994101    5462 sshutil.go:53] new ssh client: &{IP:localhost Port:33481 SSHKeyPath:/home/vikas121/.minikube/machines/minikube/id_rsa Username:docker}
I0131 13:26:44.091094    5462 ssh_runner.go:195] Run: cat /version.json
I0131 13:26:44.091160    5462 sshutil.go:53] new ssh client: &{IP:localhost Port:33481 SSHKeyPath:/home/vikas121/.minikube/machines/minikube/id_rsa Username:docker}
I0131 13:26:46.162293    5462 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (2.168509838s)
I0131 13:26:46.182801    5462 ssh_runner.go:235] Completed: cat /version.json: (2.091624892s)
W0131 13:26:46.248444    5462 start.go:840] [curl -sS -m 2 https://registry.k8s.io/] failed: curl -sS -m 2 https://registry.k8s.io/: Process exited with status 28
stdout:

stderr:
curl: (28) Operation timed out after 2002 milliseconds with 0 out of 0 bytes received
I0131 13:26:46.261889    5462 ssh_runner.go:195] Run: systemctl --version
W0131 13:26:46.278108    5462 out.go:239] ❗  This VM is having trouble accessing https://registry.k8s.io
W0131 13:26:46.278232    5462 out.go:239] 💡  To pull new external images, you may need to configure a proxy: https://minikube.sigs.k8s.io/docs/reference/networking/proxy/
W0131 13:26:46.278628    5462 out.go:239] ❗  Due to DNS issues your cluster may have problems starting and you may not be able to pull images
More details available at: https://minikube.sigs.k8s.io/docs/drivers/qemu/#known-issues
I0131 13:26:46.306997    5462 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
W0131 13:26:46.330423    5462 cni.go:209] loopback cni configuration skipped: "/etc/cni/net.d/*loopback.conf*" not found
I0131 13:26:46.341295    5462 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0131 13:26:46.404976    5462 cni.go:262] disabled [/etc/cni/net.d/87-podman-bridge.conflist] bridge cni config(s)
I0131 13:26:46.405008    5462 start.go:472] detecting cgroup driver to use...
I0131 13:26:46.421703    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0131 13:26:46.653752    5462 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0131 13:26:46.696915    5462 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0131 13:26:46.754204    5462 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0131 13:26:46.754534    5462 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0131 13:26:46.796094    5462 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0131 13:26:46.829610    5462 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0131 13:26:46.849555    5462 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0131 13:26:46.872303    5462 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0131 13:26:47.048764    5462 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0131 13:26:47.091257    5462 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0131 13:26:47.123876    5462 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0131 13:26:47.144772    5462 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0131 13:26:47.450515    5462 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0131 13:26:47.501857    5462 start.go:472] detecting cgroup driver to use...
I0131 13:26:47.502233    5462 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0131 13:26:47.548317    5462 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0131 13:26:47.588828    5462 ssh_runner.go:195] Run: sudo systemctl stop -f containerd
I0131 13:26:47.630591    5462 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0131 13:26:47.664134    5462 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0131 13:26:47.723497    5462 ssh_runner.go:195] Run: sudo systemctl stop -f crio
I0131 13:26:48.008626    5462 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0131 13:26:48.061277    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0131 13:26:48.219291    5462 ssh_runner.go:195] Run: which cri-dockerd
I0131 13:26:48.234824    5462 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0131 13:26:48.270514    5462 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0131 13:26:48.336392    5462 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0131 13:26:48.652195    5462 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0131 13:26:48.943982    5462 docker.go:560] configuring docker to use "cgroupfs" as cgroup driver...
I0131 13:26:48.987310    5462 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (130 bytes)
I0131 13:26:49.053462    5462 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0131 13:26:49.362179    5462 ssh_runner.go:195] Run: sudo systemctl restart docker
I0131 13:26:57.075057    5462 ssh_runner.go:235] Completed: sudo systemctl restart docker: (7.71279301s)
I0131 13:26:57.075284    5462 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0131 13:26:57.398289    5462 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0131 13:26:57.691875    5462 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0131 13:26:57.979872    5462 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0131 13:26:58.282606    5462 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0131 13:26:58.315790    5462 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0131 13:26:58.605904    5462 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0131 13:26:58.772120    5462 start.go:519] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0131 13:26:58.772326    5462 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0131 13:26:58.785479    5462 start.go:540] Will wait 60s for crictl version
I0131 13:26:58.785646    5462 ssh_runner.go:195] Run: which crictl
I0131 13:26:58.799875    5462 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0131 13:26:58.904291    5462 start.go:556] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.7
RuntimeApiVersion:  v1
I0131 13:26:58.951715    5462 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0131 13:26:59.054975    5462 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0131 13:26:59.313901    5462 out.go:204] 🐳  Preparing Kubernetes v1.28.3 on Docker 24.0.7 ...
I0131 13:26:59.398811    5462 ssh_runner.go:195] Run: grep 10.0.2.2	host.minikube.internal$ /etc/hosts
I0131 13:26:59.414701    5462 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "10.0.2.2	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0131 13:26:59.537636    5462 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0131 13:26:59.538043    5462 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0131 13:26:59.638516    5462 docker.go:671] Got preloaded images: -- stdout --
quay.io/prometheus/pushgateway:v1.7.0
quay.io/prometheus/prometheus:v2.49.1
quay.io/prometheus-operator/prometheus-config-reloader:v0.70.0
quay.io/prometheus/node-exporter:v1.7.0
registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
quay.io/prometheus/alertmanager:v0.26.0
registry.k8s.io/metrics-server/metrics-server:<none>
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/pause:3.9
kubernetesui/dashboard:<none>
kubernetesui/metrics-scraper:<none>
gcr.io/k8s-minikube/storage-provisioner:v5
nginx:1.14.2

-- /stdout --
I0131 13:26:59.638565    5462 docker.go:601] Images already preloaded, skipping extraction
I0131 13:26:59.638705    5462 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0131 13:26:59.706570    5462 docker.go:671] Got preloaded images: -- stdout --
quay.io/prometheus/pushgateway:v1.7.0
quay.io/prometheus/prometheus:v2.49.1
quay.io/prometheus-operator/prometheus-config-reloader:v0.70.0
quay.io/prometheus/node-exporter:v1.7.0
registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
quay.io/prometheus/alertmanager:v0.26.0
registry.k8s.io/metrics-server/metrics-server:<none>
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/pause:3.9
kubernetesui/dashboard:<none>
kubernetesui/metrics-scraper:<none>
gcr.io/k8s-minikube/storage-provisioner:v5
nginx:1.14.2

-- /stdout --
I0131 13:26:59.706598    5462 cache_images.go:84] Images are preloaded, skipping loading
I0131 13:26:59.725769    5462 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0131 13:26:59.818555    5462 cni.go:84] Creating CNI manager for ""
I0131 13:26:59.818614    5462 cni.go:158] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0131 13:26:59.818688    5462 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0131 13:26:59.818757    5462 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:10.0.2.15 APIServerPort:8443 KubernetesVersion:v1.28.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "10.0.2.15"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:10.0.2.15 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0131 13:26:59.850466    5462 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.0.2.15
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 10.0.2.15
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "10.0.2.15"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.28.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0131 13:26:59.869164    5462 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.28.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=10.0.2.15

[Install]
 config:
{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0131 13:26:59.869474    5462 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.28.3
I0131 13:26:59.932803    5462 binaries.go:44] Found k8s binaries, skipping transfer
I0131 13:26:59.955739    5462 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0131 13:26:59.995597    5462 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (366 bytes)
I0131 13:27:00.066882    5462 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0131 13:27:00.114324    5462 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2082 bytes)
I0131 13:27:00.200565    5462 ssh_runner.go:195] Run: grep 10.0.2.15	control-plane.minikube.internal$ /etc/hosts
I0131 13:27:00.213839    5462 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "10.0.2.15	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0131 13:27:00.263122    5462 certs.go:56] Setting up /home/vikas121/.minikube/profiles/minikube for IP: 10.0.2.15
I0131 13:27:00.263210    5462 certs.go:190] acquiring lock for shared ca certs: {Name:mk061ce743fad6ebb57ac0b1a3b6b345c20f9033 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0131 13:27:00.320775    5462 certs.go:199] skipping minikubeCA CA generation: /home/vikas121/.minikube/ca.key
I0131 13:27:00.321602    5462 certs.go:199] skipping proxyClientCA CA generation: /home/vikas121/.minikube/proxy-client-ca.key
I0131 13:27:00.341388    5462 certs.go:315] skipping minikube-user signed cert generation: /home/vikas121/.minikube/profiles/minikube/client.key
I0131 13:27:00.342277    5462 certs.go:315] skipping minikube signed cert generation: /home/vikas121/.minikube/profiles/minikube/apiserver.key.49504c3e
I0131 13:27:00.342776    5462 certs.go:315] skipping aggregator signed cert generation: /home/vikas121/.minikube/profiles/minikube/proxy-client.key
I0131 13:27:00.361983    5462 certs.go:437] found cert: /home/vikas121/.minikube/certs/home/vikas121/.minikube/certs/ca-key.pem (1679 bytes)
I0131 13:27:00.376422    5462 certs.go:437] found cert: /home/vikas121/.minikube/certs/home/vikas121/.minikube/certs/ca.pem (1082 bytes)
I0131 13:27:00.387364    5462 certs.go:437] found cert: /home/vikas121/.minikube/certs/home/vikas121/.minikube/certs/cert.pem (1127 bytes)
I0131 13:27:00.396171    5462 certs.go:437] found cert: /home/vikas121/.minikube/certs/home/vikas121/.minikube/certs/key.pem (1679 bytes)
I0131 13:27:00.666641    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0131 13:27:00.783652    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0131 13:27:00.898569    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0131 13:27:00.981726    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0131 13:27:01.040875    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0131 13:27:01.110526    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0131 13:27:01.181787    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0131 13:27:01.239570    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0131 13:27:01.320124    5462 ssh_runner.go:362] scp /home/vikas121/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0131 13:27:01.388164    5462 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0131 13:27:01.455703    5462 ssh_runner.go:195] Run: openssl version
I0131 13:27:01.477967    5462 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0131 13:27:01.518999    5462 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0131 13:27:01.534908    5462 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Jan 19 14:24 /usr/share/ca-certificates/minikubeCA.pem
I0131 13:27:01.535048    5462 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0131 13:27:01.550912    5462 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0131 13:27:01.573457    5462 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I0131 13:27:01.582729    5462 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0131 13:27:01.607957    5462 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0131 13:27:01.630055    5462 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0131 13:27:01.644596    5462 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0131 13:27:01.668499    5462 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0131 13:27:01.689290    5462 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0131 13:27:01.701744    5462 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.32.1-amd64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:46461 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[dashboard:true default-storageclass:true metrics-server:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:builtin Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/vikas121:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0131 13:27:01.701969    5462 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0131 13:27:01.740164    5462 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0131 13:27:01.787652    5462 host.go:66] Checking if "minikube" exists ...
I0131 13:27:02.078953    5462 main.go:141] libmachine: Using SSH client type: external
I0131 13:27:02.079123    5462 main.go:141] libmachine: Using SSH private key: /home/vikas121/.minikube/machines/minikube/id_rsa (-rw-------)
I0131 13:27:02.079290    5462 main.go:141] libmachine: &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /home/vikas121/.minikube/machines/minikube/id_rsa -p 33481] /usr/bin/ssh <nil>}
I0131 13:27:02.079429    5462 main.go:141] libmachine: /usr/bin/ssh -F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /home/vikas121/.minikube/machines/minikube/id_rsa -p 33481 -f -NTL 46461:localhost:8443
I0131 13:27:03.013845    5462 kubeadm.go:419] found existing configuration files, will attempt cluster restart
I0131 13:27:03.013885    5462 kubeadm.go:636] restartCluster start
I0131 13:27:03.014020    5462 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0131 13:27:03.059120    5462 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0131 13:27:03.100625    5462 kubeconfig.go:92] found "minikube" server: "https://localhost:37987"
I0131 13:27:03.100686    5462 kubeconfig.go:135] verify returned: got: localhost:37987, want: localhost:46461
I0131 13:27:03.153500    5462 lock.go:35] WriteFile acquiring /home/vikas121/.kube/config: {Name:mk72d1ca0258f514bec9154aa4ed8c3120412d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0131 13:27:03.512598    5462 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0131 13:27:03.579830    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:03.579992    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:03.629357    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:03.629535    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:03.629680    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:03.659765    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:04.160856    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:04.161093    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:04.216543    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:04.660595    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:04.660833    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:04.712128    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:05.159947    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:05.160132    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:05.215855    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:05.660446    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:05.660726    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:05.711923    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:06.160896    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:06.161156    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:06.214992    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:06.660985    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:06.661201    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:06.712832    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:07.160564    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:07.160792    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:07.215740    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:07.660323    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:07.660542    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:07.710083    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:08.160510    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:08.160937    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:08.211096    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:08.660981    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:08.661273    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:08.711660    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:09.160593    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:09.160880    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:09.210783    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:09.660067    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:09.660309    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:09.709652    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:10.160877    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:10.161114    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:10.210421    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:10.660550    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:10.660806    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:10.709748    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:11.160599    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:11.160835    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:11.210689    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:11.660784    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:11.661075    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:11.709091    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:12.160004    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:12.160240    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:12.209764    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:12.660657    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:12.660886    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:12.710907    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:13.160460    5462 api_server.go:166] Checking apiserver status ...
I0131 13:27:13.160685    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0131 13:27:13.212774    5462 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0131 13:27:13.594455    5462 kubeadm.go:611] needs reconfigure: apiserver error: context deadline exceeded
I0131 13:27:13.594506    5462 kubeadm.go:1128] stopping kube-system containers ...
I0131 13:27:13.594708    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0131 13:27:13.663766    5462 docker.go:469] Stopping containers: [546c0268c90e d5e9b63b3303 464a8ca47cd3 4dc3c90efcea 05c1d4b7523e 624483f8195a 1611b86459c8 ec365da0fd91 9cd40e977caa 32c30d8d4c31 1315151037c3 5257d1fe0215 0ab23c020653 b981f27ddb8e 98a6ad7e3296 81ba08ff7241 680cbc1a66cc b7efb06320ac caa4281ae96e 8fc2bc448d45 d8c8299e373c]
I0131 13:27:13.663925    5462 ssh_runner.go:195] Run: docker stop 546c0268c90e d5e9b63b3303 464a8ca47cd3 4dc3c90efcea 05c1d4b7523e 624483f8195a 1611b86459c8 ec365da0fd91 9cd40e977caa 32c30d8d4c31 1315151037c3 5257d1fe0215 0ab23c020653 b981f27ddb8e 98a6ad7e3296 81ba08ff7241 680cbc1a66cc b7efb06320ac caa4281ae96e 8fc2bc448d45 d8c8299e373c
I0131 13:27:13.738233    5462 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0131 13:27:13.783858    5462 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0131 13:27:13.816737    5462 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0131 13:27:13.816939    5462 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0131 13:27:13.842730    5462 kubeadm.go:713] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0131 13:27:13.842760    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0131 13:27:17.102463    5462 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml": (3.259657863s)
I0131 13:27:17.102508    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0131 13:27:19.564171    5462 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml": (2.461621774s)
I0131 13:27:19.570501    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0131 13:27:20.224334    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0131 13:27:20.391481    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0131 13:27:20.583473    5462 api_server.go:52] waiting for apiserver process to appear ...
I0131 13:27:20.583625    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:20.617467    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:21.147313    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:21.646685    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:22.147468    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:22.647113    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:23.147365    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:23.646918    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:24.147179    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:24.646961    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:25.147435    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:25.646960    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:26.146711    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:26.647399    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:27.147435    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:27.647226    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:28.147165    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:28.647083    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:29.146873    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:29.647435    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:30.146625    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:30.647361    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:31.147587    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:31.646618    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:32.147003    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:32.647062    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:33.147651    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:33.647581    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:34.147095    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:34.646720    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:35.147229    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:35.646875    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:36.146685    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:36.647014    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:37.146779    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:37.647047    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:38.147597    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:38.646834    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:39.146763    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:39.647369    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:40.147547    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:40.646558    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:41.146883    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:41.647223    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:42.146914    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:42.646948    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:43.147315    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:43.646904    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:44.302296    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:44.647319    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:45.146633    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:45.647180    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:46.146784    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:46.646768    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:47.146833    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:47.646698    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:48.146695    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:48.646786    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:49.147282    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:49.646644    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:50.147097    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:50.647046    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:51.147202    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:51.647711    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:52.147279    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:52.646577    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:53.146985    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:53.646820    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:54.147468    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:54.647632    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:55.146576    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:55.647217    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:56.147476    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:56.646953    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:57.147074    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:57.647423    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:58.146795    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:58.647210    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:59.147281    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:27:59.646401    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:00.146934    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:00.646569    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:01.147550    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:01.646965    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:02.146726    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:02.647261    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:03.147541    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:03.647384    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:04.147391    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:04.646656    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:05.146653    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:05.647275    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:06.146824    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:06.647181    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:07.147011    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:07.647149    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:08.147182    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:08.647581    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:09.147567    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:09.647101    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:10.147248    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:10.646597    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:11.147532    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:11.647094    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:12.279404    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:12.646869    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:13.146712    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:13.971201    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:14.147177    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:14.647193    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:15.147000    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:15.646889    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:16.147378    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:16.647588    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:17.147588    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:17.646863    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:18.147343    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:18.646724    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:19.147353    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:19.647255    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:20.147377    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:28:20.712607    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0131 13:28:20.808021    5462 logs.go:284] 2 containers: [33b3eb1a4b96 464a8ca47cd3]
I0131 13:28:20.808190    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0131 13:28:20.858674    5462 logs.go:284] 2 containers: [19e2cf0f0a48 32c30d8d4c31]
I0131 13:28:20.858839    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0131 13:28:20.907886    5462 logs.go:284] 1 containers: [624483f8195a]
I0131 13:28:20.908017    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0131 13:28:20.962715    5462 logs.go:284] 1 containers: [9cd40e977caa]
I0131 13:28:20.962883    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0131 13:28:21.013532    5462 logs.go:284] 1 containers: [b981f27ddb8e]
I0131 13:28:21.013654    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0131 13:28:21.062705    5462 logs.go:284] 1 containers: [05c1d4b7523e]
I0131 13:28:21.062841    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0131 13:28:21.103082    5462 logs.go:284] 0 containers: []
W0131 13:28:21.103111    5462 logs.go:286] No container was found matching "kindnet"
I0131 13:28:21.103239    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0131 13:28:21.147380    5462 logs.go:284] 1 containers: [546c0268c90e]
I0131 13:28:21.147511    5462 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0131 13:28:21.190540    5462 logs.go:284] 1 containers: [25561b2ba487]
I0131 13:28:21.190593    5462 logs.go:123] Gathering logs for dmesg ...
I0131 13:28:21.190613    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0131 13:28:21.222418    5462 logs.go:123] Gathering logs for kube-scheduler [9cd40e977caa] ...
I0131 13:28:21.222453    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9cd40e977caa"
I0131 13:28:30.110662    5462 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 9cd40e977caa": (8.88817313s)
I0131 13:28:30.222440    5462 logs.go:123] Gathering logs for storage-provisioner [546c0268c90e] ...
I0131 13:28:30.222476    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 546c0268c90e"
I0131 13:28:31.154354    5462 logs.go:123] Gathering logs for kubelet ...
I0131 13:28:31.154393    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0131 13:28:31.389829    5462 logs.go:123] Gathering logs for describe nodes ...
I0131 13:28:31.389868    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0131 13:29:48.989018    5462 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": (1m17.599103785s)
W0131 13:29:49.413165    5462 logs.go:130] failed describe nodes: command: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig" /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig": Process exited with status 1
stdout:

stderr:
E0131 07:59:48.733004    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 07:59:48.735324    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 07:59:48.736627    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 07:59:48.739405    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 07:59:48.743325    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
The connection to the server localhost:8443 was refused - did you specify the right host or port?
 output: 
** stderr ** 
E0131 07:59:48.733004    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 07:59:48.735324    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 07:59:48.736627    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 07:59:48.739405    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 07:59:48.743325    2053 memcache.go:265] couldn't get current server API group list: Get "https://localhost:8443/api?timeout=32s": dial tcp 127.0.0.1:8443: connect: connection refused
The connection to the server localhost:8443 was refused - did you specify the right host or port?

** /stderr **
I0131 13:29:49.714120    5462 logs.go:123] Gathering logs for kubernetes-dashboard [25561b2ba487] ...
I0131 13:29:49.776628    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 25561b2ba487"
I0131 13:29:50.138882    5462 logs.go:123] Gathering logs for Docker ...
I0131 13:29:50.138945    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0131 13:29:50.459603    5462 logs.go:123] Gathering logs for kube-apiserver [33b3eb1a4b96] ...
I0131 13:29:50.459637    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 33b3eb1a4b96"
I0131 13:29:50.564204    5462 logs.go:123] Gathering logs for etcd [32c30d8d4c31] ...
I0131 13:29:50.564245    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32c30d8d4c31"
I0131 13:30:00.553900    5462 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 32c30d8d4c31": (9.989610534s)
I0131 13:30:01.494629    5462 logs.go:123] Gathering logs for coredns [624483f8195a] ...
I0131 13:30:01.494689    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 624483f8195a"
I0131 13:30:05.598790    5462 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 624483f8195a": (4.103902114s)
I0131 13:30:05.702963    5462 logs.go:123] Gathering logs for kube-proxy [b981f27ddb8e] ...
I0131 13:30:05.796869    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b981f27ddb8e"
I0131 13:30:11.607587    5462 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 b981f27ddb8e": (5.81062905s)
I0131 13:30:11.744019    5462 logs.go:123] Gathering logs for kube-controller-manager [05c1d4b7523e] ...
I0131 13:30:11.744060    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 05c1d4b7523e"
I0131 13:30:13.687818    5462 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 05c1d4b7523e": (1.943720818s)
I0131 13:30:13.810113    5462 logs.go:123] Gathering logs for kube-apiserver [464a8ca47cd3] ...
I0131 13:30:13.810149    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 464a8ca47cd3"
I0131 13:30:16.683023    5462 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 464a8ca47cd3": (2.872829622s)
I0131 13:30:16.790308    5462 logs.go:123] Gathering logs for etcd [19e2cf0f0a48] ...
I0131 13:30:16.790344    5462 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 19e2cf0f0a48"
I0131 13:30:17.793016    5462 ssh_runner.go:235] Completed: /bin/bash -c "docker logs --tail 400 19e2cf0f0a48": (1.002605511s)
I0131 13:30:17.824546    5462 logs.go:123] Gathering logs for container status ...
I0131 13:30:17.840347    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0131 13:30:19.308140    5462 ssh_runner.go:235] Completed: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a": (1.467737327s)
I0131 13:30:22.000773    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:30:22.114257    5462 api_server.go:72] duration metric: took 3m1.530773168s to wait for apiserver process to appear ...
I0131 13:30:22.153299    5462 api_server.go:88] waiting for apiserver healthz status ...
I0131 13:30:22.250502    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:28.157944    5462 api_server.go:269] stopped: https://localhost:46461/healthz: Get "https://localhost:46461/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0131 13:30:28.328805    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:33.329849    5462 api_server.go:269] stopped: https://localhost:46461/healthz: Get "https://localhost:46461/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0131 13:30:33.830703    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:35.253890    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[-]poststarthook/start-service-ip-repair-controllers failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:35.653563    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[-]poststarthook/start-service-ip-repair-controllers failed: reason withheld
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:35.653670    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:36.046897    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:36.109743    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:36.109824    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:36.207241    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:36.207321    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:36.330811    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:36.411836    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:36.411902    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:36.830710    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:36.904696    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:36.904741    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:37.330684    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:37.485388    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:37.485436    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:37.830735    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:37.969767    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:37.969808    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:38.330316    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:38.524589    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:38.524642    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:38.830526    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:38.872229    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:38.872284    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:39.330774    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:39.371336    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:39.371443    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:39.830426    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:39.976030    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:39.976093    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:40.330512    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:40.506313    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:40.506376    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:40.830508    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:40.966093    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:40.966132    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:41.330394    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:41.376164    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:41.376214    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:41.830793    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:41.920203    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:41.920276    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:42.330146    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:42.392635    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:42.392699    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:42.830476    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:42.864917    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:42.864974    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:43.330791    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:43.396726    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:43.396768    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:43.830564    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:43.925058    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:43.925107    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:44.330929    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:44.358193    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:44.358254    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:44.830405    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:44.924285    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:44.924330    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:45.330782    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:45.450269    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:45.450335    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:45.830601    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:45.871713    5462 api_server.go:279] https://localhost:46461/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
W0131 13:30:45.871814    5462 api_server.go:103] status: https://localhost:46461/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/start-service-ip-repair-controllers ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-system-namespaces-controller ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/start-kube-apiserver-identity-lease-controller ok
[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok
[+]poststarthook/start-legacy-token-tracking-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
[+]poststarthook/apiservice-discovery-controller ok
healthz check failed
I0131 13:30:46.330701    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:30:46.404315    5462 api_server.go:279] https://localhost:46461/healthz returned 200:
ok
I0131 13:30:48.294148    5462 api_server.go:141] control plane version: v1.28.3
I0131 13:30:48.294215    5462 api_server.go:131] duration metric: took 26.140871616s to wait for apiserver health ...
I0131 13:30:48.592404    5462 cni.go:84] Creating CNI manager for ""
I0131 13:30:48.592483    5462 cni.go:158] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0131 13:30:48.877788    5462 out.go:177] 🔗  Configuring bridge CNI (Container Networking Interface) ...
I0131 13:30:49.095565    5462 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0131 13:30:49.211536    5462 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I0131 13:30:49.396172    5462 system_pods.go:43] waiting for kube-system pods to appear ...
I0131 13:30:51.362094    5462 system_pods.go:59] 8 kube-system pods found
I0131 13:30:51.381547    5462 system_pods.go:61] "coredns-5dd5756b68-mtmvh" [2e49d32c-a78d-4ac1-b2c1-d9850499865d] Running
I0131 13:30:51.381583    5462 system_pods.go:61] "etcd-minikube" [d8ad0e01-c484-40af-bd0a-691a06bffb74] Running
I0131 13:30:51.381599    5462 system_pods.go:61] "kube-apiserver-minikube" [0d149dcc-48dc-48ae-afa3-10532654399e] Running
I0131 13:30:51.381616    5462 system_pods.go:61] "kube-controller-manager-minikube" [076ee298-a47e-4041-bf91-2a4e9854d5a7] Running
I0131 13:30:51.381633    5462 system_pods.go:61] "kube-proxy-djm5l" [42af1630-2bce-455d-beac-8dc834d59dbb] Running
I0131 13:30:51.381663    5462 system_pods.go:61] "kube-scheduler-minikube" [a9c70bea-deb6-41b8-998f-db90bbdabecc] Running
I0131 13:30:51.381679    5462 system_pods.go:61] "metrics-server-7c66d45ddc-p79c5" [60a39492-59a4-49d2-acef-ba0e1641e1bf] Running
I0131 13:30:51.381705    5462 system_pods.go:61] "storage-provisioner" [ff29e3dc-c1aa-4827-a76d-1c938684f320] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0131 13:30:51.381724    5462 system_pods.go:74] duration metric: took 1.840004541s to wait for pod list to return data ...
I0131 13:30:51.381771    5462 node_conditions.go:102] verifying NodePressure condition ...
I0131 13:30:51.497243    5462 node_conditions.go:122] node storage ephemeral capacity is 17784760Ki
I0131 13:30:51.497363    5462 node_conditions.go:123] node cpu capacity is 2
I0131 13:30:51.497401    5462 node_conditions.go:105] duration metric: took 115.618416ms to run NodePressure ...
I0131 13:30:51.497451    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I0131 13:31:21.093950    5462 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml": (29.596451902s)
I0131 13:31:21.094036    5462 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0131 13:31:21.155108    5462 ops.go:34] apiserver oom_adj: -16
I0131 13:31:21.155163    5462 kubeadm.go:640] restartCluster took 4m18.141256552s
I0131 13:31:21.155180    5462 kubeadm.go:406] StartCluster complete in 4m19.453451059s
I0131 13:31:21.247520    5462 settings.go:142] acquiring lock: {Name:mk74fe4440252231abd5a6c59facb8e6b82722af Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0131 13:31:21.528743    5462 settings.go:150] Updating kubeconfig:  /home/vikas121/.kube/config
I0131 13:31:21.939438    5462 lock.go:35] WriteFile acquiring /home/vikas121/.kube/config: {Name:mk72d1ca0258f514bec9154aa4ed8c3120412d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0131 13:31:21.997382    5462 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:true default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:true nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volumesnapshots:false]
I0131 13:31:21.997617    5462 addons.go:69] Setting dashboard=true in profile "minikube"
I0131 13:31:21.997660    5462 addons.go:231] Setting addon dashboard=true in "minikube"
W0131 13:31:21.997678    5462 addons.go:240] addon dashboard should already be in state true
I0131 13:31:22.083570    5462 addons.go:69] Setting metrics-server=true in profile "minikube"
I0131 13:31:22.083647    5462 addons.go:231] Setting addon metrics-server=true in "minikube"
W0131 13:31:22.083668    5462 addons.go:240] addon metrics-server should already be in state true
I0131 13:31:22.096858    5462 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0131 13:31:22.096917    5462 addons.go:231] Setting addon storage-provisioner=true in "minikube"
W0131 13:31:22.096937    5462 addons.go:240] addon storage-provisioner should already be in state true
I0131 13:31:22.102724    5462 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0131 13:31:22.102992    5462 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0131 13:31:22.103035    5462 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0131 13:31:22.266262    5462 host.go:66] Checking if "minikube" exists ...
I0131 13:31:22.266391    5462 host.go:66] Checking if "minikube" exists ...
I0131 13:31:22.281604    5462 host.go:66] Checking if "minikube" exists ...
I0131 13:31:22.361379    5462 config.go:182] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0131 13:31:22.683046    5462 retry.go:31] will retry after 1.140930016s: connect: dial unix /home/vikas121/.minikube/machines/minikube/monitor: connect: resource temporarily unavailable
I0131 13:31:22.684994    5462 retry.go:31] will retry after 1.327805807s: connect: dial unix /home/vikas121/.minikube/machines/minikube/monitor: connect: resource temporarily unavailable
I0131 13:31:24.013973    5462 retry.go:31] will retry after 2.213048414s: connect: dial unix /home/vikas121/.minikube/machines/minikube/monitor: connect: resource temporarily unavailable
I0131 13:31:24.214127    5462 out.go:177]     ▪ Using image docker.io/kubernetesui/dashboard:v2.7.0
I0131 13:31:24.378560    5462 out.go:177]     ▪ Using image docker.io/kubernetesui/metrics-scraper:v1.0.8
I0131 13:31:24.374958    5462 out.go:177]     ▪ Using image registry.k8s.io/metrics-server/metrics-server:v0.6.4
I0131 13:31:24.487947    5462 addons.go:231] Setting addon default-storageclass=true in "minikube"
I0131 13:31:24.538970    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-ns.yaml
I0131 13:31:24.591930    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-ns.yaml (759 bytes)
W0131 13:31:24.591939    5462 addons.go:240] addon default-storageclass should already be in state true
I0131 13:31:24.592032    5462 host.go:66] Checking if "minikube" exists ...
I0131 13:31:24.592023    5462 sshutil.go:53] new ssh client: &{IP:localhost Port:33481 SSHKeyPath:/home/vikas121/.minikube/machines/minikube/id_rsa Username:docker}
I0131 13:31:24.539556    5462 addons.go:423] installing /etc/kubernetes/addons/metrics-apiservice.yaml
I0131 13:31:24.592124    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-apiservice.yaml (424 bytes)
I0131 13:31:24.592153    5462 sshutil.go:53] new ssh client: &{IP:localhost Port:33481 SSHKeyPath:/home/vikas121/.minikube/machines/minikube/id_rsa Username:docker}
I0131 13:31:24.670510    5462 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I0131 13:31:24.670553    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0131 13:31:24.670607    5462 sshutil.go:53] new ssh client: &{IP:localhost Port:33481 SSHKeyPath:/home/vikas121/.minikube/machines/minikube/id_rsa Username:docker}
I0131 13:31:24.863741    5462 kapi.go:248] "coredns" deployment in "kube-system" namespace and "minikube" context rescaled to 1 replicas
I0131 13:31:24.863802    5462 start.go:223] Will wait 6m0s for node &{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0131 13:31:25.102937    5462 out.go:177] 🔎  Verifying Kubernetes components...
I0131 13:31:25.326460    5462 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0131 13:31:25.258187    5462 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0131 13:31:25.424464    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-clusterrole.yaml
I0131 13:31:25.424492    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-clusterrole.yaml (1001 bytes)
I0131 13:31:25.463843    5462 addons.go:423] installing /etc/kubernetes/addons/metrics-server-deployment.yaml
I0131 13:31:25.463867    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-server-deployment.yaml (1907 bytes)
I0131 13:31:25.467631    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml
I0131 13:31:25.467661    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml (1018 bytes)
I0131 13:31:25.568614    5462 addons.go:423] installing /etc/kubernetes/addons/metrics-server-rbac.yaml
I0131 13:31:25.568638    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-server-rbac.yaml (2175 bytes)
I0131 13:31:25.581230    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-configmap.yaml
I0131 13:31:25.581255    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-configmap.yaml (837 bytes)
I0131 13:31:25.825360    5462 addons.go:423] installing /etc/kubernetes/addons/metrics-server-service.yaml
I0131 13:31:25.825386    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/metrics-server-service.yaml (446 bytes)
I0131 13:31:25.908313    5462 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml
I0131 13:31:26.046046    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-dp.yaml
I0131 13:31:26.046068    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-dp.yaml (4288 bytes)
I0131 13:31:26.479409    5462 out.go:177]     ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0131 13:31:26.714860    5462 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0131 13:31:26.714915    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0131 13:31:26.714970    5462 sshutil.go:53] new ssh client: &{IP:localhost Port:33481 SSHKeyPath:/home/vikas121/.minikube/machines/minikube/id_rsa Username:docker}
I0131 13:31:26.797966    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-role.yaml
I0131 13:31:26.797991    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-role.yaml (1724 bytes)
I0131 13:31:27.474559    5462 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml": (5.371754226s)
I0131 13:31:27.497882    5462 start.go:899] CoreDNS already contains "host.minikube.internal" host record, skipping...
I0131 13:31:27.669539    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-rolebinding.yaml
I0131 13:31:27.669569    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-rolebinding.yaml (1046 bytes)
I0131 13:31:27.835521    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-sa.yaml
I0131 13:31:27.835547    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-sa.yaml (837 bytes)
I0131 13:31:27.947200    5462 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0131 13:31:28.715766    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-secret.yaml
I0131 13:31:28.715793    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-secret.yaml (1389 bytes)
I0131 13:31:29.186368    5462 addons.go:423] installing /etc/kubernetes/addons/dashboard-svc.yaml
I0131 13:31:29.186402    5462 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/dashboard-svc.yaml (1294 bytes)
I0131 13:31:29.327251    5462 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml
I0131 13:31:33.540092    5462 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (8.21332134s)
I0131 13:31:33.540836    5462 ssh_runner.go:235] Completed: sudo systemctl is-active --quiet service kubelet: (8.21430879s)
I0131 13:31:33.561978    5462 api_server.go:52] waiting for apiserver process to appear ...
I0131 13:31:33.562137    5462 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0131 13:31:42.487247    5462 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (14.539994558s)
I0131 13:31:42.487587    5462 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/metrics-apiservice.yaml -f /etc/kubernetes/addons/metrics-server-deployment.yaml -f /etc/kubernetes/addons/metrics-server-rbac.yaml -f /etc/kubernetes/addons/metrics-server-service.yaml: (16.579195436s)
I0131 13:31:42.487617    5462 addons.go:467] Verifying addon metrics-server=true in "minikube"
I0131 13:31:48.181608    5462 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/dashboard-ns.yaml -f /etc/kubernetes/addons/dashboard-clusterrole.yaml -f /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml -f /etc/kubernetes/addons/dashboard-configmap.yaml -f /etc/kubernetes/addons/dashboard-dp.yaml -f /etc/kubernetes/addons/dashboard-role.yaml -f /etc/kubernetes/addons/dashboard-rolebinding.yaml -f /etc/kubernetes/addons/dashboard-sa.yaml -f /etc/kubernetes/addons/dashboard-secret.yaml -f /etc/kubernetes/addons/dashboard-svc.yaml: (18.854290664s)
I0131 13:31:48.182001    5462 ssh_runner.go:235] Completed: sudo pgrep -xnf kube-apiserver.*minikube.*: (14.61983039s)
I0131 13:31:48.256767    5462 out.go:177] 💡  Some dashboard features require the metrics-server addon. To enable all features please run:

	minikube addons enable metrics-server	


I0131 13:31:48.256808    5462 api_server.go:72] duration metric: took 23.392953099s to wait for apiserver process to appear ...
I0131 13:31:48.256839    5462 api_server.go:88] waiting for apiserver healthz status ...
I0131 13:31:48.391008    5462 api_server.go:253] Checking apiserver healthz at https://localhost:46461/healthz ...
I0131 13:31:48.431145    5462 api_server.go:279] https://localhost:46461/healthz returned 200:
ok
I0131 13:31:48.501640    5462 out.go:177] 🌟  Enabled addons: default-storageclass, storage-provisioner, metrics-server, dashboard
I0131 13:31:48.512279    5462 api_server.go:141] control plane version: v1.28.3
I0131 13:31:48.610673    5462 api_server.go:131] duration metric: took 219.716259ms to wait for apiserver health ...
I0131 13:31:48.610686    5462 addons.go:502] enable addons completed in 26.613214411s: enabled=[default-storageclass storage-provisioner metrics-server dashboard]
I0131 13:31:48.610721    5462 system_pods.go:43] waiting for kube-system pods to appear ...
I0131 13:31:51.009339    5462 system_pods.go:59] 8 kube-system pods found
I0131 13:31:51.009386    5462 system_pods.go:61] "coredns-5dd5756b68-mtmvh" [2e49d32c-a78d-4ac1-b2c1-d9850499865d] Running / Ready:ContainersNotReady (containers with unready status: [coredns]) / ContainersReady:ContainersNotReady (containers with unready status: [coredns])
I0131 13:31:51.009401    5462 system_pods.go:61] "etcd-minikube" [d8ad0e01-c484-40af-bd0a-691a06bffb74] Running
I0131 13:31:51.009416    5462 system_pods.go:61] "kube-apiserver-minikube" [0d149dcc-48dc-48ae-afa3-10532654399e] Running
I0131 13:31:51.009435    5462 system_pods.go:61] "kube-controller-manager-minikube" [076ee298-a47e-4041-bf91-2a4e9854d5a7] Running / Ready:ContainersNotReady (containers with unready status: [kube-controller-manager]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-controller-manager])
I0131 13:31:51.009451    5462 system_pods.go:61] "kube-proxy-djm5l" [42af1630-2bce-455d-beac-8dc834d59dbb] Running / Ready:ContainersNotReady (containers with unready status: [kube-proxy]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-proxy])
I0131 13:31:51.009465    5462 system_pods.go:61] "kube-scheduler-minikube" [a9c70bea-deb6-41b8-998f-db90bbdabecc] Running
I0131 13:31:51.009481    5462 system_pods.go:61] "metrics-server-7c66d45ddc-p79c5" [60a39492-59a4-49d2-acef-ba0e1641e1bf] Running / Ready:ContainersNotReady (containers with unready status: [metrics-server]) / ContainersReady:ContainersNotReady (containers with unready status: [metrics-server])
I0131 13:31:51.009497    5462 system_pods.go:61] "storage-provisioner" [ff29e3dc-c1aa-4827-a76d-1c938684f320] Running / Ready:ContainersNotReady (containers with unready status: [storage-provisioner]) / ContainersReady:ContainersNotReady (containers with unready status: [storage-provisioner])
I0131 13:31:51.009511    5462 system_pods.go:74] duration metric: took 2.398773273s to wait for pod list to return data ...
I0131 13:31:51.009528    5462 kubeadm.go:581] duration metric: took 26.14567656s to wait for : map[apiserver:true system_pods:true] ...
I0131 13:31:51.009556    5462 node_conditions.go:102] verifying NodePressure condition ...
I0131 13:31:51.656821    5462 node_conditions.go:122] node storage ephemeral capacity is 17784760Ki
I0131 13:31:51.656861    5462 node_conditions.go:123] node cpu capacity is 2
I0131 13:31:51.656885    5462 node_conditions.go:105] duration metric: took 647.319356ms to run NodePressure ...
I0131 13:31:51.656910    5462 start.go:228] waiting for startup goroutines ...
I0131 13:31:51.656929    5462 start.go:233] waiting for cluster config update ...
I0131 13:31:51.656954    5462 start.go:242] writing updated cluster config ...
I0131 13:31:51.720557    5462 ssh_runner.go:195] Run: rm -f paused
I0131 13:32:06.363110    5462 start.go:600] kubectl: 1.29.0, cluster: 1.28.3 (minor skew: 1)
I0131 13:32:06.588071    5462 out.go:177] 🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* -- Journal begins at Wed 2024-01-31 07:55:44 UTC, ends at Wed 2024-01-31 08:44:15 UTC. --
Jan 31 08:41:45 minikube dockerd[857]: time="2024-01-31T08:41:45.852259579Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 31 08:41:45 minikube dockerd[857]: time="2024-01-31T08:41:45.852621568Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:41:45 minikube dockerd[857]: time="2024-01-31T08:41:45.852819459Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 31 08:41:45 minikube dockerd[857]: time="2024-01-31T08:41:45.852879753Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:41:46 minikube dockerd[851]: time="2024-01-31T08:41:46.164142006Z" level=error msg="Failed to compute size of container rootfs e21b44682f42f7a3bf9c47360d14c8685b66cf0c7ebddde56b55aecf33c502a4: mount does not exist"
Jan 31 08:42:40 minikube dockerd[851]: time="2024-01-31T08:42:40.413367189Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Jan 31 08:42:40 minikube dockerd[851]: time="2024-01-31T08:42:40.413451807Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Jan 31 08:42:47 minikube dockerd[851]: time="2024-01-31T08:42:47.619540353Z" level=error msg="Not continuing with pull after error: errors:\ndenied: requested access to the resource is denied\nunauthorized: authentication required\n"
Jan 31 08:42:47 minikube dockerd[851]: time="2024-01-31T08:42:47.621014724Z" level=info msg="Ignoring extra error returned from registry" error="unauthorized: authentication required"
Jan 31 08:43:00 minikube dockerd[851]: time="2024-01-31T08:43:00.493011880Z" level=info msg="ignoring event" container=687848787b2654e7f3bcbf17c9334714264d48ed68161e7a472b925532bcf6b9 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 31 08:43:00 minikube dockerd[857]: time="2024-01-31T08:43:00.495894158Z" level=info msg="shim disconnected" id=687848787b2654e7f3bcbf17c9334714264d48ed68161e7a472b925532bcf6b9 namespace=moby
Jan 31 08:43:00 minikube dockerd[857]: time="2024-01-31T08:43:00.519405406Z" level=warning msg="cleaning up after shim disconnected" id=687848787b2654e7f3bcbf17c9334714264d48ed68161e7a472b925532bcf6b9 namespace=moby
Jan 31 08:43:00 minikube dockerd[857]: time="2024-01-31T08:43:00.519471884Z" level=info msg="cleaning up dead shim" namespace=moby
Jan 31 08:43:05 minikube dockerd[851]: time="2024-01-31T08:43:05.453902503Z" level=info msg="Container failed to exit within 30s of signal 15 - using the force" container=b2233aeb78509f5ed4fe79a52ad3a5ea0f63463fc17d5b6ca4a0b2146b46526b
Jan 31 08:43:06 minikube dockerd[851]: time="2024-01-31T08:43:06.856077067Z" level=info msg="ignoring event" container=2cfa080653c0793a200e6d4f92197f00d5cde4b2d96eccb7408623f6544de2bd module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 31 08:43:06 minikube dockerd[857]: time="2024-01-31T08:43:06.865820946Z" level=info msg="shim disconnected" id=2cfa080653c0793a200e6d4f92197f00d5cde4b2d96eccb7408623f6544de2bd namespace=moby
Jan 31 08:43:06 minikube dockerd[857]: time="2024-01-31T08:43:06.867472911Z" level=warning msg="cleaning up after shim disconnected" id=2cfa080653c0793a200e6d4f92197f00d5cde4b2d96eccb7408623f6544de2bd namespace=moby
Jan 31 08:43:06 minikube dockerd[857]: time="2024-01-31T08:43:06.868492932Z" level=info msg="cleaning up dead shim" namespace=moby
Jan 31 08:43:07 minikube dockerd[851]: time="2024-01-31T08:43:07.212130471Z" level=info msg="ignoring event" container=b2233aeb78509f5ed4fe79a52ad3a5ea0f63463fc17d5b6ca4a0b2146b46526b module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 31 08:43:07 minikube dockerd[857]: time="2024-01-31T08:43:07.323120249Z" level=info msg="shim disconnected" id=b2233aeb78509f5ed4fe79a52ad3a5ea0f63463fc17d5b6ca4a0b2146b46526b namespace=moby
Jan 31 08:43:07 minikube dockerd[857]: time="2024-01-31T08:43:07.323381914Z" level=warning msg="cleaning up after shim disconnected" id=b2233aeb78509f5ed4fe79a52ad3a5ea0f63463fc17d5b6ca4a0b2146b46526b namespace=moby
Jan 31 08:43:07 minikube dockerd[857]: time="2024-01-31T08:43:07.323436001Z" level=info msg="cleaning up dead shim" namespace=moby
Jan 31 08:43:13 minikube dockerd[851]: time="2024-01-31T08:43:13.326864395Z" level=info msg="ignoring event" container=90dad179ab653b23ed4dd806f138eaa1cb14a2cb8f483002acda4ada587f7c07 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 31 08:43:13 minikube dockerd[857]: time="2024-01-31T08:43:13.336963193Z" level=info msg="shim disconnected" id=90dad179ab653b23ed4dd806f138eaa1cb14a2cb8f483002acda4ada587f7c07 namespace=moby
Jan 31 08:43:13 minikube dockerd[857]: time="2024-01-31T08:43:13.339383255Z" level=warning msg="cleaning up after shim disconnected" id=90dad179ab653b23ed4dd806f138eaa1cb14a2cb8f483002acda4ada587f7c07 namespace=moby
Jan 31 08:43:13 minikube dockerd[857]: time="2024-01-31T08:43:13.339702714Z" level=info msg="cleaning up dead shim" namespace=moby
Jan 31 08:43:16 minikube dockerd[857]: time="2024-01-31T08:43:16.032061680Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 31 08:43:16 minikube dockerd[857]: time="2024-01-31T08:43:16.033887691Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:16 minikube dockerd[857]: time="2024-01-31T08:43:16.033952981Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 31 08:43:16 minikube dockerd[857]: time="2024-01-31T08:43:16.033987661Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:17 minikube dockerd[857]: time="2024-01-31T08:43:17.638916891Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 31 08:43:17 minikube dockerd[857]: time="2024-01-31T08:43:17.639066711Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:17 minikube dockerd[857]: time="2024-01-31T08:43:17.640069432Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 31 08:43:17 minikube dockerd[857]: time="2024-01-31T08:43:17.640365961Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:19 minikube dockerd[857]: time="2024-01-31T08:43:19.664365664Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 31 08:43:19 minikube dockerd[857]: time="2024-01-31T08:43:19.665875103Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:19 minikube dockerd[857]: time="2024-01-31T08:43:19.666134684Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 31 08:43:19 minikube dockerd[857]: time="2024-01-31T08:43:19.666376578Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:21 minikube cri-dockerd[1099]: time="2024-01-31T08:43:21Z" level=error msg="Error response from daemon: No such container: eb4814278722b9ad488a44a9c2f825025011d1d96d0cb1b03d5556b5204b7439 Failed to get stats from container eb4814278722b9ad488a44a9c2f825025011d1d96d0cb1b03d5556b5204b7439"
Jan 31 08:43:23 minikube dockerd[851]: time="2024-01-31T08:43:23.220828224Z" level=error msg="Failed to compute size of container rootfs 69d0ba42732bb6baf68c0e0def6d1800575a97981ebbaa661a11fd1c98c5a124: mount does not exist"
Jan 31 08:43:25 minikube dockerd[857]: time="2024-01-31T08:43:25.375326589Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 31 08:43:25 minikube dockerd[857]: time="2024-01-31T08:43:25.375591217Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:25 minikube dockerd[857]: time="2024-01-31T08:43:25.375637829Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 31 08:43:25 minikube dockerd[857]: time="2024-01-31T08:43:25.375669316Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:27 minikube dockerd[857]: time="2024-01-31T08:43:27.452324266Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 31 08:43:27 minikube dockerd[857]: time="2024-01-31T08:43:27.496948822Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:27 minikube dockerd[857]: time="2024-01-31T08:43:27.559741876Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 31 08:43:27 minikube dockerd[857]: time="2024-01-31T08:43:27.560175357Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:33 minikube dockerd[857]: time="2024-01-31T08:43:33.990660522Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 31 08:43:33 minikube dockerd[857]: time="2024-01-31T08:43:33.991875840Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:43:34 minikube dockerd[857]: time="2024-01-31T08:43:34.011688249Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 31 08:43:34 minikube dockerd[857]: time="2024-01-31T08:43:34.012021604Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 31 08:44:00 minikube dockerd[851]: time="2024-01-31T08:44:00.383638045Z" level=info msg="ignoring event" container=d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 31 08:44:00 minikube dockerd[857]: time="2024-01-31T08:44:00.386249557Z" level=info msg="shim disconnected" id=d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74 namespace=moby
Jan 31 08:44:00 minikube dockerd[857]: time="2024-01-31T08:44:00.386449233Z" level=warning msg="cleaning up after shim disconnected" id=d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74 namespace=moby
Jan 31 08:44:00 minikube dockerd[857]: time="2024-01-31T08:44:00.386477591Z" level=info msg="cleaning up dead shim" namespace=moby
Jan 31 08:44:01 minikube dockerd[851]: time="2024-01-31T08:44:01.558521336Z" level=info msg="ignoring event" container=dd67eabddbfdd3b2acd20e66b2247686f71bee4703381c7e6e959cbb446cbfa3 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 31 08:44:01 minikube dockerd[857]: time="2024-01-31T08:44:01.558588539Z" level=info msg="shim disconnected" id=dd67eabddbfdd3b2acd20e66b2247686f71bee4703381c7e6e959cbb446cbfa3 namespace=moby
Jan 31 08:44:01 minikube dockerd[857]: time="2024-01-31T08:44:01.558705793Z" level=warning msg="cleaning up after shim disconnected" id=dd67eabddbfdd3b2acd20e66b2247686f71bee4703381c7e6e959cbb446cbfa3 namespace=moby
Jan 31 08:44:01 minikube dockerd[857]: time="2024-01-31T08:44:01.558731560Z" level=info msg="cleaning up dead shim" namespace=moby

* 
* ==> container status <==
* time="2024-01-31T08:45:00Z" level=fatal msg="validate service connection: validate CRI v1 runtime API for endpoint \"unix:///var/run/cri-dockerd.sock\": rpc error: code = DeadlineExceeded desc = context deadline exceeded"
CONTAINER ID   IMAGE                       COMMAND                  CREATED              STATUS                          PORTS     NAMES
d248809e053f   a608c686bac9                "/metrics-server --c…"   27 seconds ago       Up 3 seconds                              k8s_metrics-server_metrics-server-7c66d45ddc-p79c5_kube-system_60a39492-59a4-49d2-acef-ba0e1641e1bf_103
3b03f66d71ce   07655ddf2eeb                "/dashboard --insecu…"   27 seconds ago       Created                                   k8s_kubernetes-dashboard_kubernetes-dashboard-8694d4445c-z4ghh_kubernetes-dashboard_09c87280-9b02-434e-bb80-093807bc6281_85
8e449a9f4d71   9f27df16978d                "/bin/alertmanager -…"   53 seconds ago       Up 20 seconds                             k8s_alertmanager_prometheus-alertmanager-0_default_b5bbc4d1-ff2a-47e9-a631-7784be4e9dcf_54
a0247b02c893   07655ddf2eeb                "/dashboard --insecu…"   About a minute ago   Exited (2) 34 seconds ago                 k8s_kubernetes-dashboard_kubernetes-dashboard-8694d4445c-z4ghh_kubernetes-dashboard_09c87280-9b02-434e-bb80-093807bc6281_84
dd67eabddbfd   9f27df16978d                "/bin/alertmanager -…"   About a minute ago   Exited (2) 59 seconds ago                 k8s_alertmanager_prometheus-alertmanager-0_default_b5bbc4d1-ff2a-47e9-a631-7784be4e9dcf_53
d04083f72576   f5f9f4739d5f                "/kube-state-metrics…"   About a minute ago   Exited (2) About a minute ago             k8s_kube-state-metrics_prometheus-kube-state-metrics-745b475957-k9mgr_default_eb5b48b8-87a4-43fd-9b8a-a814701ebdf2_70
d6d34f966d43   537434729123                "kube-apiserver --ad…"   About a minute ago   Up About a minute                         k8s_kube-apiserver_kube-apiserver-minikube_kube-system_842672fed952e0ab68deac178344590a_46
faa4de385c52   6e38f40d628d                "/storage-provisioner"   2 minutes ago        Up About a minute                         k8s_storage-provisioner_storage-provisioner_kube-system_ff29e3dc-c1aa-4827-a76d-1c938684f320_94
76dabeb962b9   a608c686bac9                "/metrics-server --c…"   2 minutes ago        Exited (137) 32 seconds ago               k8s_metrics-server_metrics-server-7c66d45ddc-p79c5_kube-system_60a39492-59a4-49d2-acef-ba0e1641e1bf_102
81ebde99ad3c   6e38f40d628d                "/storage-provisioner"   4 minutes ago        Exited (1) 4 minutes ago                  k8s_storage-provisioner_storage-provisioner_kube-system_ff29e3dc-c1aa-4827-a76d-1c938684f320_93
f3e1577f51d1   2a72b385beaf                "/bin/prometheus --s…"   4 minutes ago        Up 4 minutes                              k8s_prometheus-server_prometheus-server-bc7ccb595-kqsqh_default_ca62ceb2-3bb5-485b-bd4c-54a8fc4254f3_14
687848787b26   537434729123                "kube-apiserver --ad…"   6 minutes ago        Exited (255) 2 minutes ago                k8s_kube-apiserver_kube-apiserver-minikube_kube-system_842672fed952e0ab68deac178344590a_45
d6f53c2bc445   registry.k8s.io/pause:3.9   "/pause"                 14 minutes ago       Up 14 minutes                             k8s_POD_books-app-deployment-5c866bfb66-n2g56_default_562eb7ee-e162-4bb5-b8e0-6df700769d61_1
23725ff54193   registry.k8s.io/pause:3.9   "/pause"                 14 minutes ago       Up 14 minutes                             k8s_POD_books-app-deployment-5c866bfb66-z9f8g_default_a8bd7447-867c-47ea-9207-e9d822180bb7_1
8aac432088c1   ead0a4a53df8                "/coredns -conf /etc…"   40 minutes ago       Up 39 minutes                             k8s_coredns_coredns-5dd5756b68-mtmvh_kube-system_2e49d32c-a78d-4ac1-b2c1-d9850499865d_16
2deea46bd390   8ea0b8616c54                "/bin/pushgateway"       41 minutes ago       Up 40 minutes                             k8s_pushgateway_prometheus-prometheus-pushgateway-6ccd698d79-lxh6g_default_eb128846-eb6f-4498-8196-55e2cf376cbf_12
ed05c539ba64   115053965e86                "/metrics-sidecar"       41 minutes ago       Up 40 minutes                             k8s_dashboard-metrics-scraper_dashboard-metrics-scraper-7fd5cb4ddc-dltn7_kubernetes-dashboard_c879249e-bcf7-4a66-9679-aa539e3939e5_22
14cb00e53e19   115053965e86                "/metrics-sidecar"       42 minutes ago       Exited (2) 41 minutes ago                 k8s_dashboard-metrics-scraper_dashboard-metrics-scraper-7fd5cb4ddc-dltn7_kubernetes-dashboard_c879249e-bcf7-4a66-9679-aa539e3939e5_21
8a7e25b0b6ec   73ec9f309a82                "/bin/prometheus-con…"   42 minutes ago       Up 42 minutes                             k8s_prometheus-server-configmap-reload_prometheus-server-bc7ccb595-kqsqh_default_ca62ceb2-3bb5-485b-bd4c-54a8fc4254f3_4
e438290e8a8d   8ea0b8616c54                "/bin/pushgateway"       43 minutes ago       Exited (2) 42 minutes ago                 k8s_pushgateway_prometheus-prometheus-pushgateway-6ccd698d79-lxh6g_default_eb128846-eb6f-4498-8196-55e2cf376cbf_11
67a74ce18974   bfc896cf80fb                "/usr/local/bin/kube…"   43 minutes ago       Up 43 minutes                             k8s_kube-proxy_kube-proxy-djm5l_kube-system_42af1630-2bce-455d-beac-8dc834d59dbb_14
531005ca8669   72c9c2088986                "/bin/node_exporter …"   43 minutes ago       Up 43 minutes                             k8s_node-exporter_prometheus-prometheus-node-exporter-q99rd_default_9e3bbb0f-5220-4259-8540-e4f261742b5b_51
afc5fcc3a4cd   registry.k8s.io/pause:3.9   "/pause"                 43 minutes ago       Up 42 minutes                             k8s_POD_prometheus-server-bc7ccb595-kqsqh_default_ca62ceb2-3bb5-485b-bd4c-54a8fc4254f3_8
d56ac6d5a414   10baa1ca1706                "kube-controller-man…"   43 minutes ago       Up 43 minutes                             k8s_kube-controller-manager_kube-controller-manager-minikube_kube-system_11fc41667a2819cdb15b7270cb5cd200_36
52b7e3ea7730   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_prometheus-prometheus-pushgateway-6ccd698d79-lxh6g_default_eb128846-eb6f-4498-8196-55e2cf376cbf_8
f1837b24f61d   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_prometheus-alertmanager-0_default_b5bbc4d1-ff2a-47e9-a631-7784be4e9dcf_7
8d6b4c71eb77   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 42 minutes                             k8s_POD_dashboard-metrics-scraper-7fd5cb4ddc-dltn7_kubernetes-dashboard_c879249e-bcf7-4a66-9679-aa539e3939e5_15
74cbd831cc23   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_kubernetes-dashboard-8694d4445c-z4ghh_kubernetes-dashboard_09c87280-9b02-434e-bb80-093807bc6281_16
29a09d8368b8   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_coredns-5dd5756b68-mtmvh_kube-system_2e49d32c-a78d-4ac1-b2c1-d9850499865d_17
41ac577431b7   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_prometheus-kube-state-metrics-745b475957-k9mgr_default_eb5b48b8-87a4-43fd-9b8a-a814701ebdf2_7
470dbf623cf1   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_metrics-server-7c66d45ddc-p79c5_kube-system_60a39492-59a4-49d2-acef-ba0e1641e1bf_15
3bf8347c518e   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_kube-proxy-djm5l_kube-system_42af1630-2bce-455d-beac-8dc834d59dbb_15
f7ede640aad7   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_prometheus-prometheus-node-exporter-q99rd_default_9e3bbb0f-5220-4259-8540-e4f261742b5b_5
0a880b343eb3   registry.k8s.io/pause:3.9   "/pause"                 44 minutes ago       Up 43 minutes                             k8s_POD_storage-provisioner_kube-system_ff29e3dc-c1aa-4827-a76d-1c938684f320_15
5864505bbbcb   10baa1ca1706                "kube-controller-man…"   46 minutes ago       Exited (1) 44 minutes ago                 k8s_kube-controller-manager_kube-controller-manager-minikube_kube-system_11fc41667a2819cdb15b7270cb5cd200_35
95474da4beb7   6d1b4fd1b182                "kube-scheduler --au…"   46 minutes ago       Up 46 minutes                             k8s_kube-scheduler_kube-scheduler-minikube_kube-system_75ac196d3709dde303d8a81c035c2c28_14
19e2cf0f0a48   73deb9a3f702                "etcd --advertise-cl…"   46 minutes ago       Up 46 minutes                             k8s_etcd_etcd-minikube_kube-system_d751ca6ec9cbeb15e51b214833bee7cc_15
b8947cc78e02   registry.k8s.io/pause:3.9   "/pause"                 47 minutes ago       Up 46 minutes                             k8s_POD_kube-scheduler-minikube_kube-system_75ac196d3709dde303d8a81c035c2c28_17
2bfd618dbb7d   registry.k8s.io/pause:3.9   "/pause"                 47 minutes ago       Up 46 minutes                             k8s_POD_kube-controller-manager-minikube_kube-system_11fc41667a2819cdb15b7270cb5cd200_17
6092fddbff61   registry.k8s.io/pause:3.9   "/pause"                 47 minutes ago       Up 47 minutes                             k8s_POD_etcd-minikube_kube-system_d751ca6ec9cbeb15e51b214833bee7cc_16
3a6567379e4d   registry.k8s.io/pause:3.9   "/pause"                 47 minutes ago       Up 47 minutes                             k8s_POD_kube-apiserver-minikube_kube-system_842672fed952e0ab68deac178344590a_15
4473108ddf73   72c9c2088986                "/bin/node_exporter …"   6 days ago           Exited (255) 48 minutes ago               k8s_node-exporter_prometheus-prometheus-node-exporter-q99rd_default_9e3bbb0f-5220-4259-8540-e4f261742b5b_50
9cd40e977caa   6d1b4fd1b182                "kube-scheduler --au…"   6 days ago           Exited (255) 48 minutes ago               k8s_kube-scheduler_kube-scheduler-minikube_kube-system_75ac196d3709dde303d8a81c035c2c28_13
32c30d8d4c31   73deb9a3f702                "etcd --advertise-cl…"   6 days ago           Exited (255) 48 minutes ago               k8s_etcd_etcd-minikube_kube-system_d751ca6ec9cbeb15e51b214833bee7cc_14
1315151037c3   registry.k8s.io/pause:3.9   "/pause"                 6 days ago           Exited (255) 48 minutes ago               k8s_POD_kube-scheduler-minikube_kube-system_75ac196d3709dde303d8a81c035c2c28_16
0ab23c020653   registry.k8s.io/pause:3.9   "/pause"                 6 days ago           Exited (255) 48 minutes ago               k8s_POD_etcd-minikube_kube-system_d751ca6ec9cbeb15e51b214833bee7cc_15
b981f27ddb8e   bfc896cf80fb                "/usr/local/bin/kube…"   6 days ago           Exited (255) 48 minutes ago               k8s_kube-proxy_kube-proxy-djm5l_kube-system_42af1630-2bce-455d-beac-8dc834d59dbb_13
6add55b735fd   registry.k8s.io/pause:3.9   "/pause"                 6 days ago           Exited (255) 48 minutes ago               k8s_POD_prometheus-prometheus-node-exporter-q99rd_default_9e3bbb0f-5220-4259-8540-e4f261742b5b_4
81ba08ff7241   registry.k8s.io/pause:3.9   "/pause"                 6 days ago           Exited (255) 48 minutes ago               k8s_POD_kube-proxy-djm5l_kube-system_42af1630-2bce-455d-beac-8dc834d59dbb_14

* 
* ==> coredns [8aac432088c1] <==
* [INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: watch of *v1.Namespace ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[INFO] plugin/kubernetes: Waited for 2.399392297s due to client-side throttling, not priority and fairness, request: GET:https://10.96.0.1:443/api/v1/namespaces?resourceVersion=30849
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 4.666860293s
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?resourceVersion=30823": net/http: TLS handshake timeout
[INFO] plugin/kubernetes: Trace[2087383393]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169 (31-Jan-2024 08:37:06.825) (total time: 32253ms):
Trace[2087383393]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/services?resourceVersion=30823": net/http: TLS handshake timeout 32223ms (08:37:39.049)
Trace[2087383393]: [32.253760462s] [32.253760462s] END
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?resourceVersion=30829": net/http: TLS handshake timeout
[INFO] plugin/kubernetes: Trace[1673128382]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169 (31-Jan-2024 08:37:09.936) (total time: 29620ms):
Trace[1673128382]: ---"Objects listed" error:Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?resourceVersion=30829": net/http: TLS handshake timeout 29619ms (08:37:39.556)
Trace[1673128382]: [29.620723442s] [29.620723442s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?resourceVersion=30829": net/http: TLS handshake timeout
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?resourceVersion=30823": net/http: TLS handshake timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?resourceVersion=30849": net/http: TLS handshake timeout
[INFO] plugin/kubernetes: Trace[148900610]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169 (31-Jan-2024 08:37:06.837) (total time: 33748ms):
Trace[148900610]: ---"Objects listed" error:Get "https://10.96.0.1:443/api/v1/namespaces?resourceVersion=30849": net/http: TLS handshake timeout 33748ms (08:37:40.585)
Trace[148900610]: [33.748436947s] [33.748436947s] END
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?resourceVersion=30849": net/http: TLS handshake timeout
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.664314753s
[INFO] plugin/kubernetes: Trace[1160902307]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169 (31-Jan-2024 08:37:42.628) (total time: 10778ms):
Trace[1160902307]: ---"Objects listed" error:<nil> 10778ms (08:37:53.406)
Trace[1160902307]: [10.778328051s] [10.778328051s] END
[INFO] plugin/kubernetes: Trace[293211741]: "DeltaFIFO Pop Process" ID:default/kubernetes,Depth:11,Reason:slow event handlers blocking the queue (31-Jan-2024 08:37:51.071) (total time: 2523ms):
Trace[293211741]: [2.523334265s] [2.523334265s] END
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: Failed to watch *v1.Service: unknown (get services) - error from a previous attempt: net/http: TLS handshake timeout
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: Failed to watch *v1.Namespace: unknown (get namespaces) - error from a previous attempt: net/http: TLS handshake timeout
[ERROR] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169: Failed to watch *v1.EndpointSlice: unknown (get endpointslices.discovery.k8s.io) - error from a previous attempt: net/http: TLS handshake timeout
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.076512444s
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 2.16491377s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.681794772s
[INFO] 10.244.0.112:36116 - 31795 "A IN prometheus-prometheus-pushgateway.default.svc.default.svc.cluster.local. udp 100 false 1232" NXDOMAIN qr,aa,rd 182 3.570130266s
[INFO] 10.244.0.112:37919 - 55593 "AAAA IN prometheus-prometheus-pushgateway.default.svc.default.svc.cluster.local. udp 100 false 1232" NXDOMAIN qr,aa,rd 182 3.003488989s
[INFO] 10.244.0.112:43547 - 152 "A IN prometheus-prometheus-pushgateway.default.svc.default.svc.cluster.local. udp 100 false 1232" NXDOMAIN qr,aa,rd 182 3.158888322s
[INFO] 10.244.0.112:45353 - 16897 "AAAA IN prometheus-prometheus-pushgateway.default.svc.default.svc.cluster.local. udp 100 false 1232" NXDOMAIN qr,aa,rd 182 3.305086249s
[INFO] plugin/kubernetes: Trace[1969754066]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169 (31-Jan-2024 08:43:46.538) (total time: 15837ms):
Trace[1969754066]: ---"Objects listed" error:<nil> 15837ms (08:44:02.376)
Trace[1969754066]: [15.837958817s] [15.837958817s] END
[INFO] plugin/kubernetes: Trace[581366513]: "Reflector ListAndWatch" name:pkg/mod/k8s.io/client-go@v0.26.1/tools/cache/reflector.go:169 (31-Jan-2024 08:43:45.963) (total time: 16635ms):
Trace[581366513]: ---"Objects listed" error:<nil> 14358ms (08:44:00.321)
Trace[581366513]: ---"Objects extracted" 2277ms (08:44:02.599)
Trace[581366513]: [16.635987681s] [16.635987681s] END
[WARNING] plugin/health: Local health request to "http://:8080/health" failed: Get "http://:8080/health": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
[INFO] 10.244.0.112:54995 - 37818 "A IN kubernetes.default.svc.svc.cluster.local. udp 69 false 1232" NXDOMAIN qr,aa,rd 151 0.000968351s
[INFO] 10.244.0.112:54947 - 26753 "AAAA IN kubernetes.default.svc.cluster.local. udp 65 false 1232" NOERROR qr,aa,rd 147 0.435682175s
[INFO] 10.244.0.112:54333 - 43677 "A IN kubernetes.default.svc.cluster.local. udp 65 false 1232" NOERROR qr,aa,rd 106 0.612682047s
[INFO] 10.244.0.112:38012 - 51960 "A IN prometheus-prometheus-pushgateway.default.svc.default.svc.cluster.local. udp 100 false 1232" NXDOMAIN qr,aa,rd 182 0.000417007s
[INFO] 10.244.0.112:38635 - 32637 "AAAA IN prometheus-prometheus-pushgateway.default.svc.default.svc.cluster.local. udp 100 false 1232" NXDOMAIN qr,aa,rd 182 0.000961118s
[INFO] 10.244.0.112:40338 - 14425 "A IN prometheus-prometheus-pushgateway.default.svc.svc.cluster.local. udp 92 false 1232" NXDOMAIN qr,aa,rd 174 0.000360612s
[INFO] 10.244.0.112:38657 - 42736 "AAAA IN prometheus-prometheus-pushgateway.default.svc.svc.cluster.local. udp 92 false 1232" NXDOMAIN qr,aa,rd 174 0.000205466s
[INFO] 10.244.0.112:33632 - 9550 "A IN prometheus-prometheus-pushgateway.default.svc.cluster.local. udp 88 false 1232" NOERROR qr,aa,rd 152 0.000259577s
[INFO] 10.244.0.112:58734 - 9517 "AAAA IN prometheus-prometheus-pushgateway.default.svc.cluster.local. udp 88 false 1232" NOERROR qr,aa,rd 170 0.000292047s
[WARNING] plugin/health: Local health request to "http://:8080/health" took more than 1s: 1.092279842s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=8220a6eb95f0a4d75f7f2d7b14cef975f050512d
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2024_01_19T19_55_54_0700
                    minikube.k8s.io/version=v1.32.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Fri, 19 Jan 2024 14:25:00 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 31 Jan 2024 08:45:56 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 31 Jan 2024 08:42:53 +0000   Wed, 31 Jan 2024 08:42:53 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 31 Jan 2024 08:42:53 +0000   Wed, 31 Jan 2024 08:42:53 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 31 Jan 2024 08:42:53 +0000   Wed, 31 Jan 2024 08:42:53 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 31 Jan 2024 08:42:53 +0000   Wed, 31 Jan 2024 08:42:53 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  10.0.2.15
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  17784760Ki
  hugepages-2Mi:      0
  memory:             2165920Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  17784760Ki
  hugepages-2Mi:      0
  memory:             2165920Ki
  pods:               110
System Info:
  Machine ID:                 a51f8cff58bc4b248883c60ffa958cf2
  System UUID:                a51f8cff58bc4b248883c60ffa958cf2
  Boot ID:                    2dabd53b-1a69-4061-b12b-d0be08062393
  Kernel Version:             5.10.57
  OS Image:                   Buildroot 2021.02.12
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://24.0.7
  Kubelet Version:            v1.28.3
  Kube-Proxy Version:         v1.28.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (17 in total)
  Namespace                   Name                                                  CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                                  ------------  ----------  ---------------  -------------  ---
  default                     books-app-deployment-5c866bfb66-n2g56                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17m
  default                     books-app-deployment-5c866bfb66-z9f8g                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         17m
  default                     prometheus-alertmanager-0                             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d19h
  default                     prometheus-kube-state-metrics-745b475957-k9mgr        0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d19h
  default                     prometheus-prometheus-node-exporter-q99rd             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d19h
  default                     prometheus-prometheus-pushgateway-6ccd698d79-lxh6g    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d19h
  default                     prometheus-server-bc7ccb595-kqsqh                     0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7d19h
  kube-system                 coredns-5dd5756b68-mtmvh                              100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (3%!)(MISSING)        170Mi (8%!)(MISSING)     11d
  kube-system                 etcd-minikube                                         100m (5%!)(MISSING)     0 (0%!)(MISSING)      100Mi (4%!)(MISSING)       0 (0%!)(MISSING)         11d
  kube-system                 kube-apiserver-minikube                               250m (12%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kube-system                 kube-controller-manager-minikube                      200m (10%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kube-system                 kube-proxy-djm5l                                      0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kube-system                 kube-scheduler-minikube                               100m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kube-system                 metrics-server-7c66d45ddc-p79c5                       100m (5%!)(MISSING)     0 (0%!)(MISSING)      200Mi (9%!)(MISSING)       0 (0%!)(MISSING)         10d
  kube-system                 storage-provisioner                                   0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kubernetes-dashboard        dashboard-metrics-scraper-7fd5cb4ddc-dltn7            0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
  kubernetes-dashboard        kubernetes-dashboard-8694d4445c-z4ghh                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11d
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests     Limits
  --------           --------     ------
  cpu                850m (42%!)(MISSING)   0 (0%!)(MISSING)
  memory             370Mi (17%!)(MISSING)  170Mi (8%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)       0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)       0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                    From             Message
  ----    ------                   ----                   ----             -------
  Normal  Starting                 42m                    kube-proxy       
  Normal  NodeNotReady             6d14h (x3 over 6d21h)  kubelet          Node minikube status is now: NodeNotReady
  Normal  NodeReady                6d14h (x8 over 6d21h)  kubelet          Node minikube status is now: NodeReady
  Normal  NodeAllocatableEnforced  48m                    kubelet          Updated Node Allocatable limit across pods
  Normal  RegisteredNode           43m                    node-controller  Node minikube event: Registered Node minikube in Controller
  Normal  NodeHasSufficientMemory  3m12s (x61 over 48m)   kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    3m12s (x61 over 48m)   kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     3m12s (x61 over 48m)   kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeReady                3m12s (x2 over 44m)    kubelet          Node minikube status is now: NodeReady
  Normal  NodeNotReady             3m9s                   node-controller  Node minikube status is now: NodeNotReady

* 
* ==> dmesg <==
* [Jan31 07:55] You have booted with nomodeset. This means your GPU drivers are DISABLED
[  +0.000002] Any video related functionality will be severely degraded, and you may not even be able to suspend the system properly
[  +0.000002] Unless you actually understand what nomodeset does, you should reboot without enabling it
[ +11.899348] platform regulatory.0: Direct firmware load for regulatory.db failed with error -2
[  +8.170780] systemd-fstab-generator[113]: Ignoring "noauto" for root device
[  +0.236598] systemd[1]: systemd-journald.service: unit configures an IP firewall, but the local system does not support BPF/cgroup firewalling.
[  +0.000006] systemd[1]: (This warning is only shown for the first unit using IP firewalling.)
[  +5.933728] NFSD: Using /var/lib/nfs/v4recovery as the NFSv4 state recovery directory
[  +0.000026] NFSD: unable to find recovery directory /var/lib/nfs/v4recovery
[  +0.000003] NFSD: Unable to initialize client recovery tracking! (-2)
[  +9.361803] systemd-fstab-generator[508]: Ignoring "noauto" for root device
[  +0.304627] systemd-fstab-generator[519]: Ignoring "noauto" for root device
[Jan31 07:56] kauditd_printk_skb: 18 callbacks suppressed
[  +4.911349] systemd-fstab-generator[779]: Ignoring "noauto" for root device
[  +1.202959] systemd-fstab-generator[817]: Ignoring "noauto" for root device
[  +0.292281] systemd-fstab-generator[828]: Ignoring "noauto" for root device
[  +0.423667] systemd-fstab-generator[841]: Ignoring "noauto" for root device
[  +8.009028] systemd-fstab-generator[1044]: Ignoring "noauto" for root device
[  +0.318028] systemd-fstab-generator[1055]: Ignoring "noauto" for root device
[  +0.280713] systemd-fstab-generator[1066]: Ignoring "noauto" for root device
[  +0.302046] systemd-fstab-generator[1077]: Ignoring "noauto" for root device
[  +0.332709] systemd-fstab-generator[1091]: Ignoring "noauto" for root device
[Jan31 07:57] systemd-fstab-generator[1316]: Ignoring "noauto" for root device
[ +16.408632] kauditd_printk_skb: 29 callbacks suppressed
[Jan31 08:01] kauditd_printk_skb: 5 callbacks suppressed
[Jan31 08:03] kauditd_printk_skb: 10 callbacks suppressed
[  +7.518523] hrtimer: interrupt took 1790800 ns
[Jan31 08:04] kauditd_printk_skb: 10 callbacks suppressed

* 
* ==> etcd [19e2cf0f0a48] <==
* {"level":"warn","ts":"2024-01-31T08:45:59.430356Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:45:58.75225Z","time spent":"678.040087ms","remote":"127.0.0.1:49678","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":110,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/masterleases/10.0.2.15\" mod_revision:31225 > success:<request_put:<key:\"/registry/masterleases/10.0.2.15\" value_size:62 lease:5991350316438197411 >> failure:<request_range:<key:\"/registry/masterleases/10.0.2.15\" > >"}
{"level":"warn","ts":"2024-01-31T08:45:59.783139Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"198.448833ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350316438197425 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" mod_revision:31244 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" value_size:768 lease:5991350316438197322 >> failure:<request_range:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" > >>","response":"size:18"}
{"level":"info","ts":"2024-01-31T08:45:59.783355Z","caller":"traceutil/trace.go:171","msg":"trace[654197939] linearizableReadLoop","detail":"{readStateIndex:39199; appliedIndex:39198; }","duration":"262.849508ms","start":"2024-01-31T08:45:59.52048Z","end":"2024-01-31T08:45:59.78333Z","steps":["trace[654197939] 'read index received'  (duration: 63.952599ms)","trace[654197939] 'applied index is now lower than readState.Index'  (duration: 198.893227ms)"],"step_count":2}
{"level":"info","ts":"2024-01-31T08:45:59.783569Z","caller":"traceutil/trace.go:171","msg":"trace[981963426] transaction","detail":"{read_only:false; response_revision:31247; number_of_response:1; }","duration":"265.730228ms","start":"2024-01-31T08:45:59.517815Z","end":"2024-01-31T08:45:59.783545Z","steps":["trace[981963426] 'process raft request'  (duration: 66.745746ms)","trace[981963426] 'compare'  (duration: 198.128768ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-31T08:45:59.786057Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"265.584621ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/\" range_end:\"/registry/masterleases0\" ","response":"range_response_count:1 size:128"}
{"level":"info","ts":"2024-01-31T08:45:59.786184Z","caller":"traceutil/trace.go:171","msg":"trace[323928555] range","detail":"{range_begin:/registry/masterleases/; range_end:/registry/masterleases0; response_count:1; response_revision:31247; }","duration":"265.737425ms","start":"2024-01-31T08:45:59.520416Z","end":"2024-01-31T08:45:59.786154Z","steps":["trace[323928555] 'agreement among raft nodes before linearized reading'  (duration: 263.606415ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:45:59.786683Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"262.098528ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-31T08:45:59.786729Z","caller":"traceutil/trace.go:171","msg":"trace[1508369343] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:31247; }","duration":"262.149137ms","start":"2024-01-31T08:45:59.524566Z","end":"2024-01-31T08:45:59.786715Z","steps":["trace[1508369343] 'agreement among raft nodes before linearized reading'  (duration: 262.052131ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:00.629719Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"687.103066ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350316438197431 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" mod_revision:31247 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" value_size:768 lease:5991350316438197322 >> failure:<request_range:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" > >>","response":"size:18"}
{"level":"info","ts":"2024-01-31T08:46:00.629973Z","caller":"traceutil/trace.go:171","msg":"trace[974835530] linearizableReadLoop","detail":"{readStateIndex:39200; appliedIndex:39199; }","duration":"799.016121ms","start":"2024-01-31T08:45:59.830916Z","end":"2024-01-31T08:46:00.629932Z","steps":["trace[974835530] 'read index received'  (duration: 111.448628ms)","trace[974835530] 'applied index is now lower than readState.Index'  (duration: 687.559978ms)"],"step_count":2}
{"level":"info","ts":"2024-01-31T08:46:00.632163Z","caller":"traceutil/trace.go:171","msg":"trace[944141373] transaction","detail":"{read_only:false; response_revision:31248; number_of_response:1; }","duration":"807.103156ms","start":"2024-01-31T08:45:59.824997Z","end":"2024-01-31T08:46:00.6321Z","steps":["trace[944141373] 'process raft request'  (duration: 117.500358ms)","trace[944141373] 'compare'  (duration: 680.233652ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-31T08:46:00.632587Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:45:59.824962Z","time spent":"807.390272ms","remote":"127.0.0.1:49700","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":846,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" mod_revision:31247 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" value_size:768 lease:5991350316438197322 >> failure:<request_range:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" > >"}
{"level":"warn","ts":"2024-01-31T08:46:03.105922Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.99985636s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"","error":"context canceled"}
{"level":"info","ts":"2024-01-31T08:46:03.106049Z","caller":"traceutil/trace.go:171","msg":"trace[1884226816] range","detail":"{range_begin:/registry/health; range_end:; }","duration":"2.000014438s","start":"2024-01-31T08:46:01.106006Z","end":"2024-01-31T08:46:03.106021Z","steps":["trace[1884226816] 'agreement among raft nodes before linearized reading'  (duration: 1.999852143s)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:03.106135Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:01.105971Z","time spent":"2.000142643s","remote":"127.0.0.1:49664","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":0,"request content":"key:\"/registry/health\" "}
WARNING: 2024/01/31 08:46:03 [core] grpc: Server.processUnaryRPC failed to write status: connection error: desc = "transport is closing"
{"level":"warn","ts":"2024-01-31T08:46:03.621715Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"2.581485873s","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350316438197434 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" mod_revision:31248 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" value_size:768 lease:5991350316438197322 >> failure:<request_range:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" > >>","response":"size:18"}
{"level":"info","ts":"2024-01-31T08:46:03.622537Z","caller":"traceutil/trace.go:171","msg":"trace[1358890562] linearizableReadLoop","detail":"{readStateIndex:39201; appliedIndex:39200; }","duration":"2.960651072s","start":"2024-01-31T08:46:00.661852Z","end":"2024-01-31T08:46:03.622503Z","steps":["trace[1358890562] 'read index received'  (duration: 378.03891ms)","trace[1358890562] 'applied index is now lower than readState.Index'  (duration: 2.582606651s)"],"step_count":2}
{"level":"info","ts":"2024-01-31T08:46:03.623265Z","caller":"traceutil/trace.go:171","msg":"trace[1161303316] transaction","detail":"{read_only:false; response_revision:31249; number_of_response:1; }","duration":"2.968242808s","start":"2024-01-31T08:46:00.654959Z","end":"2024-01-31T08:46:03.623202Z","steps":["trace[1161303316] 'process raft request'  (duration: 385.099558ms)","trace[1161303316] 'compare'  (duration: 2.57682491s)"],"step_count":2}
{"level":"warn","ts":"2024-01-31T08:46:03.623646Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:00.654897Z","time spent":"2.96850391s","remote":"127.0.0.1:49700","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":846,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" mod_revision:31248 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" value_size:768 lease:5991350316438197322 >> failure:<request_range:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" > >"}
{"level":"warn","ts":"2024-01-31T08:46:03.624498Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"2.963148407s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" ","response":"range_response_count:1 size:1112"}
{"level":"info","ts":"2024-01-31T08:46:03.624575Z","caller":"traceutil/trace.go:171","msg":"trace[1663430064] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:31249; }","duration":"2.963232824s","start":"2024-01-31T08:46:00.661321Z","end":"2024-01-31T08:46:03.624554Z","steps":["trace[1663430064] 'agreement among raft nodes before linearized reading'  (duration: 2.963010767s)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:03.624644Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:00.660852Z","time spent":"2.963767867s","remote":"127.0.0.1:49748","response type":"/etcdserverpb.KV/Range","request count":0,"request size":67,"response count":1,"response size":1136,"request content":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" "}
{"level":"warn","ts":"2024-01-31T08:46:04.466402Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"716.902612ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350316438197435 > lease_revoke:<id:53258d5e88391472>","response":"size:30"}
{"level":"info","ts":"2024-01-31T08:46:04.467335Z","caller":"traceutil/trace.go:171","msg":"trace[41766749] transaction","detail":"{read_only:false; response_revision:31250; number_of_response:1; }","duration":"827.479991ms","start":"2024-01-31T08:46:03.639805Z","end":"2024-01-31T08:46:04.467285Z","steps":["trace[41766749] 'process raft request'  (duration: 826.866774ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:04.469026Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:03.639701Z","time spent":"827.719405ms","remote":"127.0.0.1:49748","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":1094,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" mod_revision:31243 > success:<request_put:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" value_size:1021 >> failure:<request_range:<key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" > >"}
{"level":"info","ts":"2024-01-31T08:46:04.469878Z","caller":"traceutil/trace.go:171","msg":"trace[939355749] linearizableReadLoop","detail":"{readStateIndex:39202; appliedIndex:39201; }","duration":"847.114306ms","start":"2024-01-31T08:46:03.622718Z","end":"2024-01-31T08:46:04.469832Z","steps":["trace[939355749] 'read index received'  (duration: 126.445458ms)","trace[939355749] 'applied index is now lower than readState.Index'  (duration: 720.661241ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-31T08:46:04.470954Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"1.364422745s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-31T08:46:04.471135Z","caller":"traceutil/trace.go:171","msg":"trace[436411436] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:31250; }","duration":"1.364555656s","start":"2024-01-31T08:46:03.106482Z","end":"2024-01-31T08:46:04.471038Z","steps":["trace[436411436] 'agreement among raft nodes before linearized reading'  (duration: 1.364345989s)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:04.471341Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:03.106463Z","time spent":"1.364827313s","remote":"127.0.0.1:49666","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":30,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2024-01-31T08:46:04.472008Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"2.978453017s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/prioritylevelconfigurations/\" range_end:\"/registry/prioritylevelconfigurations0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2024-01-31T08:46:04.472116Z","caller":"traceutil/trace.go:171","msg":"trace[1364999975] range","detail":"{range_begin:/registry/prioritylevelconfigurations/; range_end:/registry/prioritylevelconfigurations0; response_count:0; response_revision:31250; }","duration":"2.978578859s","start":"2024-01-31T08:46:01.493504Z","end":"2024-01-31T08:46:04.472083Z","steps":["trace[1364999975] 'agreement among raft nodes before linearized reading'  (duration: 2.978306707s)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:04.473644Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:01.493299Z","time spent":"2.978893085s","remote":"127.0.0.1:49874","response type":"/etcdserverpb.KV/Range","request count":0,"request size":82,"response count":8,"response size":32,"request content":"key:\"/registry/prioritylevelconfigurations/\" range_end:\"/registry/prioritylevelconfigurations0\" count_only:true "}
{"level":"warn","ts":"2024-01-31T08:46:04.474604Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"3.173716276s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumeclaims/\" range_end:\"/registry/persistentvolumeclaims0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2024-01-31T08:46:04.474759Z","caller":"traceutil/trace.go:171","msg":"trace[1326472724] range","detail":"{range_begin:/registry/persistentvolumeclaims/; range_end:/registry/persistentvolumeclaims0; response_count:0; response_revision:31250; }","duration":"3.173901902s","start":"2024-01-31T08:46:01.300813Z","end":"2024-01-31T08:46:04.474715Z","steps":["trace[1326472724] 'agreement among raft nodes before linearized reading'  (duration: 3.173568172s)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:04.474899Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:01.300783Z","time spent":"3.174068918s","remote":"127.0.0.1:49744","response type":"/etcdserverpb.KV/Range","request count":0,"request size":72,"response count":2,"response size":32,"request content":"key:\"/registry/persistentvolumeclaims/\" range_end:\"/registry/persistentvolumeclaims0\" count_only:true "}
{"level":"warn","ts":"2024-01-31T08:46:04.478034Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"835.269634ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" ","response":"range_response_count:1 size:864"}
{"level":"info","ts":"2024-01-31T08:46:04.478287Z","caller":"traceutil/trace.go:171","msg":"trace[1459653914] range","detail":"{range_begin:/registry/events/kube-system/metrics-server.17af620d9622ea74; range_end:; response_count:1; response_revision:31250; }","duration":"835.491179ms","start":"2024-01-31T08:46:03.642676Z","end":"2024-01-31T08:46:04.478167Z","steps":["trace[1459653914] 'agreement among raft nodes before linearized reading'  (duration: 835.118113ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:04.478434Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:03.642649Z","time spent":"835.744853ms","remote":"127.0.0.1:49700","response type":"/etcdserverpb.KV/Range","request count":0,"request size":62,"response count":1,"response size":888,"request content":"key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" "}
{"level":"warn","ts":"2024-01-31T08:46:04.668523Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"4.837602809s","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/\" range_end:\"/registry/events0\" limit:500 ","response":"range_response_count:269 size:218202"}
{"level":"info","ts":"2024-01-31T08:46:04.669017Z","caller":"traceutil/trace.go:171","msg":"trace[133633858] range","detail":"{range_begin:/registry/events/; range_end:/registry/events0; response_count:269; response_revision:31248; }","duration":"4.838121176s","start":"2024-01-31T08:45:59.830857Z","end":"2024-01-31T08:46:04.668978Z","steps":["trace[133633858] 'agreement among raft nodes before linearized reading'  (duration: 799.199141ms)","trace[133633858] 'range keys from bolt db'  (duration: 4.037785736s)"],"step_count":2}
{"level":"warn","ts":"2024-01-31T08:46:04.669289Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:45:59.830826Z","time spent":"4.838265064s","remote":"127.0.0.1:49700","response type":"/etcdserverpb.KV/Range","request count":0,"request size":41,"response count":269,"response size":218226,"request content":"key:\"/registry/events/\" range_end:\"/registry/events0\" limit:500 "}
{"level":"warn","ts":"2024-01-31T08:46:04.866024Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"231.144912ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350316438197440 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" mod_revision:31249 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" value_size:768 lease:5991350316438197322 >> failure:<request_range:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" > >>","response":"size:18"}
{"level":"info","ts":"2024-01-31T08:46:04.867494Z","caller":"traceutil/trace.go:171","msg":"trace[124619168] linearizableReadLoop","detail":"{readStateIndex:39204; appliedIndex:39203; }","duration":"333.557163ms","start":"2024-01-31T08:46:04.5339Z","end":"2024-01-31T08:46:04.867457Z","steps":["trace[124619168] 'read index received'  (duration: 100.578699ms)","trace[124619168] 'applied index is now lower than readState.Index'  (duration: 232.97059ms)"],"step_count":2}
{"level":"info","ts":"2024-01-31T08:46:04.868347Z","caller":"traceutil/trace.go:171","msg":"trace[1106382315] transaction","detail":"{read_only:false; response_revision:31251; number_of_response:1; }","duration":"368.397415ms","start":"2024-01-31T08:46:04.499922Z","end":"2024-01-31T08:46:04.86832Z","steps":["trace[1106382315] 'process raft request'  (duration: 134.649176ms)","trace[1106382315] 'compare'  (duration: 230.575048ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-31T08:46:04.868878Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:04.499866Z","time spent":"368.576513ms","remote":"127.0.0.1:49700","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":846,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" mod_revision:31249 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" value_size:768 lease:5991350316438197322 >> failure:<request_range:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" > >"}
{"level":"warn","ts":"2024-01-31T08:46:04.870373Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"336.484884ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-31T08:46:04.871647Z","caller":"traceutil/trace.go:171","msg":"trace[441706788] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:31251; }","duration":"337.75731ms","start":"2024-01-31T08:46:04.533838Z","end":"2024-01-31T08:46:04.871595Z","steps":["trace[441706788] 'agreement among raft nodes before linearized reading'  (duration: 336.063487ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-31T08:46:04.872305Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:04.533808Z","time spent":"338.361745ms","remote":"127.0.0.1:49664","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":30,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2024-01-31T08:46:04.881772Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"187.317627ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/\" range_end:\"/registry/events0\" limit:500 ","response":"range_response_count:269 size:218202"}
{"level":"info","ts":"2024-01-31T08:46:04.883571Z","caller":"traceutil/trace.go:171","msg":"trace[1324512246] range","detail":"{range_begin:/registry/events/; range_end:/registry/events0; response_count:269; response_revision:31251; }","duration":"189.000568ms","start":"2024-01-31T08:46:04.693834Z","end":"2024-01-31T08:46:04.882835Z","steps":["trace[1324512246] 'agreement among raft nodes before linearized reading'  (duration: 177.292895ms)"],"step_count":1}
{"level":"info","ts":"2024-01-31T08:46:05.319681Z","caller":"traceutil/trace.go:171","msg":"trace[1892064017] linearizableReadLoop","detail":"{readStateIndex:39205; appliedIndex:39204; }","duration":"226.725449ms","start":"2024-01-31T08:46:05.092917Z","end":"2024-01-31T08:46:05.319642Z","steps":["trace[1892064017] 'read index received'  (duration: 163.834258ms)","trace[1892064017] 'applied index is now lower than readState.Index'  (duration: 62.889133ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-31T08:46:05.321511Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"228.669107ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/leases/kube-node-lease/minikube\" ","response":"range_response_count:1 size:538"}
{"level":"info","ts":"2024-01-31T08:46:05.322281Z","caller":"traceutil/trace.go:171","msg":"trace[1921798393] range","detail":"{range_begin:/registry/leases/kube-node-lease/minikube; range_end:; response_count:1; response_revision:31252; }","duration":"229.455946ms","start":"2024-01-31T08:46:05.092787Z","end":"2024-01-31T08:46:05.322243Z","steps":["trace[1921798393] 'agreement among raft nodes before linearized reading'  (duration: 228.325386ms)"],"step_count":1}
{"level":"info","ts":"2024-01-31T08:46:05.323139Z","caller":"traceutil/trace.go:171","msg":"trace[1927511457] transaction","detail":"{read_only:false; response_revision:31252; number_of_response:1; }","duration":"397.190749ms","start":"2024-01-31T08:46:04.92591Z","end":"2024-01-31T08:46:05.323101Z","steps":["trace[1927511457] 'process raft request'  (duration: 330.495953ms)","trace[1927511457] 'compare'  (duration: 62.736265ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-31T08:46:05.323749Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:04.925756Z","time spent":"397.850428ms","remote":"127.0.0.1:49700","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":846,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" mod_revision:31251 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" value_size:768 lease:5991350316438197322 >> failure:<request_range:<key:\"/registry/events/kube-system/metrics-server.17af620d9622ea74\" > >"}
{"level":"warn","ts":"2024-01-31T08:46:06.270702Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"813.388515ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350316438197447 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af621377bee397\" mod_revision:0 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af621377bee397\" value_size:814 lease:5991350316438197322 >> failure:<>>","response":"size:18"}
{"level":"info","ts":"2024-01-31T08:46:06.272717Z","caller":"traceutil/trace.go:171","msg":"trace[1403914857] linearizableReadLoop","detail":"{readStateIndex:39206; appliedIndex:39205; }","duration":"205.118434ms","start":"2024-01-31T08:46:06.067527Z","end":"2024-01-31T08:46:06.272646Z","steps":["trace[1403914857] 'read index received'  (duration: 103.199µs)","trace[1403914857] 'applied index is now lower than readState.Index'  (duration: 205.004484ms)"],"step_count":2}
{"level":"info","ts":"2024-01-31T08:46:06.274119Z","caller":"traceutil/trace.go:171","msg":"trace[777127003] transaction","detail":"{read_only:false; response_revision:31253; number_of_response:1; }","duration":"937.031266ms","start":"2024-01-31T08:46:05.337023Z","end":"2024-01-31T08:46:06.274054Z","steps":["trace[777127003] 'process raft request'  (duration: 120.013598ms)","trace[777127003] 'compare'  (duration: 495.61914ms)","trace[777127003] 'store kv pair into bolt db' {req_type:put; key:/registry/events/kube-system/metrics-server.17af621377bee397; req_size:889; } (duration: 317.362683ms)"],"step_count":3}
{"level":"warn","ts":"2024-01-31T08:46:06.274627Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-31T08:46:05.336977Z","time spent":"937.517279ms","remote":"127.0.0.1:49700","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":892,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/kube-system/metrics-server.17af621377bee397\" mod_revision:0 > success:<request_put:<key:\"/registry/events/kube-system/metrics-server.17af621377bee397\" value_size:814 lease:5991350316438197322 >> failure:<>"}

* 
* ==> etcd [32c30d8d4c31] <==
* {"level":"info","ts":"2024-01-24T18:42:01.099198Z","caller":"traceutil/trace.go:171","msg":"trace[1345909012] range","detail":"{range_begin:/registry/pods/default/prometheus-prometheus-node-exporter-q99rd; range_end:; response_count:1; response_revision:28860; }","duration":"1.574448728s","start":"2024-01-24T18:41:59.524014Z","end":"2024-01-24T18:42:01.098464Z","steps":["trace[1345909012] 'agreement among raft nodes before linearized reading'  (duration: 1.573413925s)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:01.099686Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:41:59.523959Z","time spent":"1.575621809s","remote":"127.0.0.1:40932","response type":"/etcdserverpb.KV/Range","request count":0,"request size":66,"response count":1,"response size":5800,"request content":"key:\"/registry/pods/default/prometheus-prometheus-node-exporter-q99rd\" "}
{"level":"warn","ts":"2024-01-24T18:42:01.101639Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"482.514975ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-24T18:42:01.104411Z","caller":"traceutil/trace.go:171","msg":"trace[695733160] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:28860; }","duration":"485.286483ms","start":"2024-01-24T18:42:00.619036Z","end":"2024-01-24T18:42:01.104323Z","steps":["trace[695733160] 'agreement among raft nodes before linearized reading'  (duration: 482.290576ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:01.107107Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:00.618999Z","time spent":"487.950439ms","remote":"127.0.0.1:40884","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":30,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2024-01-24T18:42:01.863049Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"584.210182ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/default/prometheus-prometheus-node-exporter-q99rd.17ad45861e428d67\" ","response":"range_response_count:1 size:893"}
{"level":"info","ts":"2024-01-24T18:42:01.863262Z","caller":"traceutil/trace.go:171","msg":"trace[1481297880] range","detail":"{range_begin:/registry/events/default/prometheus-prometheus-node-exporter-q99rd.17ad45861e428d67; range_end:; response_count:1; response_revision:28860; }","duration":"584.454552ms","start":"2024-01-24T18:42:01.278756Z","end":"2024-01-24T18:42:01.863211Z","steps":["trace[1481297880] 'range keys from in-memory index tree'  (duration: 582.967815ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:01.863421Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:01.278696Z","time spent":"584.672938ms","remote":"127.0.0.1:40904","response type":"/etcdserverpb.KV/Range","request count":0,"request size":85,"response count":1,"response size":917,"request content":"key:\"/registry/events/default/prometheus-prometheus-node-exporter-q99rd.17ad45861e428d67\" "}
{"level":"warn","ts":"2024-01-24T18:42:01.864356Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"156.176381ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-24T18:42:01.864473Z","caller":"traceutil/trace.go:171","msg":"trace[811366855] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:28860; }","duration":"156.305729ms","start":"2024-01-24T18:42:01.708135Z","end":"2024-01-24T18:42:01.864441Z","steps":["trace[811366855] 'range keys from in-memory index tree'  (duration: 155.935752ms)"],"step_count":1}
{"level":"info","ts":"2024-01-24T18:42:02.76509Z","caller":"traceutil/trace.go:171","msg":"trace[1425502541] linearizableReadLoop","detail":"{readStateIndex:36325; appliedIndex:36324; }","duration":"214.287606ms","start":"2024-01-24T18:42:02.550748Z","end":"2024-01-24T18:42:02.765037Z","steps":["trace[1425502541] 'read index received'  (duration: 212.792272ms)","trace[1425502541] 'applied index is now lower than readState.Index'  (duration: 1.489371ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-24T18:42:02.766233Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"209.174526ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/validatingwebhookconfigurations/\" range_end:\"/registry/validatingwebhookconfigurations0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-24T18:42:02.766584Z","caller":"traceutil/trace.go:171","msg":"trace[353150432] range","detail":"{range_begin:/registry/validatingwebhookconfigurations/; range_end:/registry/validatingwebhookconfigurations0; response_count:0; response_revision:28860; }","duration":"209.437806ms","start":"2024-01-24T18:42:02.556972Z","end":"2024-01-24T18:42:02.766411Z","steps":["trace[353150432] 'agreement among raft nodes before linearized reading'  (duration: 208.711459ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:02.768143Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"200.149804ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-24T18:42:02.768336Z","caller":"traceutil/trace.go:171","msg":"trace[1509588039] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:28860; }","duration":"200.348326ms","start":"2024-01-24T18:42:02.567936Z","end":"2024-01-24T18:42:02.768285Z","steps":["trace[1509588039] 'agreement among raft nodes before linearized reading'  (duration: 200.071301ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:02.768235Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"217.733794ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:419"}
{"level":"info","ts":"2024-01-24T18:42:02.770844Z","caller":"traceutil/trace.go:171","msg":"trace[2110806158] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:28860; }","duration":"220.327445ms","start":"2024-01-24T18:42:02.550459Z","end":"2024-01-24T18:42:02.770787Z","steps":["trace[2110806158] 'agreement among raft nodes before linearized reading'  (duration: 217.529901ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:03.279024Z","caller":"etcdserver/v3_server.go:897","msg":"waiting for ReadIndex response took too long, retrying","sent-request-id":5991350167651666895,"retry-timeout":"500ms"}
{"level":"info","ts":"2024-01-24T18:42:03.585034Z","caller":"traceutil/trace.go:171","msg":"trace[1169607216] linearizableReadLoop","detail":"{readStateIndex:36326; appliedIndex:36325; }","duration":"806.729317ms","start":"2024-01-24T18:42:02.778257Z","end":"2024-01-24T18:42:03.584986Z","steps":["trace[1169607216] 'read index received'  (duration: 737.820912ms)","trace[1169607216] 'applied index is now lower than readState.Index'  (duration: 68.899637ms)"],"step_count":2}
{"level":"info","ts":"2024-01-24T18:42:03.588439Z","caller":"traceutil/trace.go:171","msg":"trace[640340986] transaction","detail":"{read_only:false; response_revision:28861; number_of_response:1; }","duration":"815.911303ms","start":"2024-01-24T18:42:02.772466Z","end":"2024-01-24T18:42:03.588378Z","steps":["trace[640340986] 'process raft request'  (duration: 743.819149ms)","trace[640340986] 'compare'  (duration: 66.354984ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-24T18:42:03.590169Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:02.772419Z","time spent":"817.590944ms","remote":"127.0.0.1:40904","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":875,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/default/prometheus-prometheus-node-exporter-q99rd.17ad45861e428d67\" mod_revision:28541 > success:<request_put:<key:\"/registry/events/default/prometheus-prometheus-node-exporter-q99rd.17ad45861e428d67\" value_size:774 lease:5991350167651666891 >> failure:<request_range:<key:\"/registry/events/default/prometheus-prometheus-node-exporter-q99rd.17ad45861e428d67\" > >"}
{"level":"warn","ts":"2024-01-24T18:42:03.589574Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"811.2102ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/masterleases/\" range_end:\"/registry/masterleases0\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-24T18:42:03.592403Z","caller":"traceutil/trace.go:171","msg":"trace[1494481777] range","detail":"{range_begin:/registry/masterleases/; range_end:/registry/masterleases0; response_count:0; response_revision:28861; }","duration":"814.186778ms","start":"2024-01-24T18:42:02.77817Z","end":"2024-01-24T18:42:03.592357Z","steps":["trace[1494481777] 'agreement among raft nodes before linearized reading'  (duration: 808.280867ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:03.593041Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:02.778121Z","time spent":"814.852158ms","remote":"127.0.0.1:40892","response type":"/etcdserverpb.KV/Range","request count":0,"request size":50,"response count":0,"response size":30,"request content":"key:\"/registry/masterleases/\" range_end:\"/registry/masterleases0\" "}
{"level":"warn","ts":"2024-01-24T18:42:05.048409Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"716.107202ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350167651666899 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce7f6833c\" mod_revision:28847 > success:<request_put:<key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce7f6833c\" value_size:744 lease:5991350167651666891 >> failure:<request_range:<key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce7f6833c\" > >>","response":"size:18"}
{"level":"info","ts":"2024-01-24T18:42:05.048763Z","caller":"traceutil/trace.go:171","msg":"trace[2053758701] linearizableReadLoop","detail":"{readStateIndex:36327; appliedIndex:36326; }","duration":"524.138533ms","start":"2024-01-24T18:42:04.524578Z","end":"2024-01-24T18:42:05.048716Z","steps":["trace[2053758701] 'read index received'  (duration: 138.184µs)","trace[2053758701] 'applied index is now lower than readState.Index'  (duration: 523.991512ms)"],"step_count":2}
{"level":"info","ts":"2024-01-24T18:42:05.049065Z","caller":"traceutil/trace.go:171","msg":"trace[764021889] transaction","detail":"{read_only:false; response_revision:28862; number_of_response:1; }","duration":"1.440964259s","start":"2024-01-24T18:42:03.608049Z","end":"2024-01-24T18:42:05.049013Z","steps":["trace[764021889] 'process raft request'  (duration: 724.020269ms)","trace[764021889] 'compare'  (duration: 714.945492ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-24T18:42:05.04928Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:03.608002Z","time spent":"1.441149003s","remote":"127.0.0.1:40904","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":829,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce7f6833c\" mod_revision:28847 > success:<request_put:<key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce7f6833c\" value_size:744 lease:5991350167651666891 >> failure:<request_range:<key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce7f6833c\" > >"}
{"level":"warn","ts":"2024-01-24T18:42:05.050137Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"525.744931ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/certificatesigningrequests/\" range_end:\"/registry/certificatesigningrequests0\" count_only:true ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-24T18:42:05.050254Z","caller":"traceutil/trace.go:171","msg":"trace[814530363] range","detail":"{range_begin:/registry/certificatesigningrequests/; range_end:/registry/certificatesigningrequests0; response_count:0; response_revision:28862; }","duration":"525.882254ms","start":"2024-01-24T18:42:04.524336Z","end":"2024-01-24T18:42:05.050219Z","steps":["trace[814530363] 'agreement among raft nodes before linearized reading'  (duration: 525.53711ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:05.050404Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:04.52428Z","time spent":"526.067284ms","remote":"127.0.0.1:40950","response type":"/etcdserverpb.KV/Range","request count":0,"request size":80,"response count":0,"response size":30,"request content":"key:\"/registry/certificatesigningrequests/\" range_end:\"/registry/certificatesigningrequests0\" count_only:true "}
{"level":"warn","ts":"2024-01-24T18:42:05.051203Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"470.022908ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2024-01-24T18:42:05.051324Z","caller":"traceutil/trace.go:171","msg":"trace[296276968] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:28862; }","duration":"470.142721ms","start":"2024-01-24T18:42:04.581139Z","end":"2024-01-24T18:42:05.051282Z","steps":["trace[296276968] 'agreement among raft nodes before linearized reading'  (duration: 469.929192ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:05.051574Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:04.581095Z","time spent":"470.354193ms","remote":"127.0.0.1:40884","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":30,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2024-01-24T18:42:05.938132Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"748.146237ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14\" ","response":"range_response_count:1 size:846"}
{"level":"info","ts":"2024-01-24T18:42:05.939253Z","caller":"traceutil/trace.go:171","msg":"trace[862813287] range","detail":"{range_begin:/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14; range_end:; response_count:1; response_revision:28862; }","duration":"749.222365ms","start":"2024-01-24T18:42:05.189896Z","end":"2024-01-24T18:42:05.939119Z","steps":["trace[862813287] 'range keys from in-memory index tree'  (duration: 747.623501ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:05.940084Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:05.189839Z","time spent":"750.165623ms","remote":"127.0.0.1:40904","response type":"/etcdserverpb.KV/Range","request count":0,"request size":69,"response count":1,"response size":870,"request content":"key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14\" "}
{"level":"warn","ts":"2024-01-24T18:42:05.942088Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"599.802997ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/persistentvolumeclaims/\" range_end:\"/registry/persistentvolumeclaims0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2024-01-24T18:42:05.943333Z","caller":"traceutil/trace.go:171","msg":"trace[1662850716] range","detail":"{range_begin:/registry/persistentvolumeclaims/; range_end:/registry/persistentvolumeclaims0; response_count:0; response_revision:28862; }","duration":"600.934862ms","start":"2024-01-24T18:42:05.342209Z","end":"2024-01-24T18:42:05.943145Z","steps":["trace[1662850716] 'count revisions from in-memory index tree'  (duration: 599.197615ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:05.944238Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:05.342148Z","time spent":"601.973506ms","remote":"127.0.0.1:40926","response type":"/etcdserverpb.KV/Range","request count":0,"request size":72,"response count":2,"response size":32,"request content":"key:\"/registry/persistentvolumeclaims/\" range_end:\"/registry/persistentvolumeclaims0\" count_only:true "}
{"level":"info","ts":"2024-01-24T18:42:06.18975Z","caller":"traceutil/trace.go:171","msg":"trace[2015405235] transaction","detail":"{read_only:false; response_revision:28863; number_of_response:1; }","duration":"169.413247ms","start":"2024-01-24T18:42:06.020293Z","end":"2024-01-24T18:42:06.189708Z","steps":["trace[2015405235] 'process raft request'  (duration: 169.140538ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:06.643204Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"215.681216ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350167651666906 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14\" mod_revision:28573 > success:<request_put:<key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14\" value_size:743 lease:5991350167651666891 >> failure:<request_range:<key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14\" > >>","response":"size:18"}
{"level":"info","ts":"2024-01-24T18:42:06.643979Z","caller":"traceutil/trace.go:171","msg":"trace[695113669] linearizableReadLoop","detail":"{readStateIndex:36330; appliedIndex:36328; }","duration":"447.50248ms","start":"2024-01-24T18:42:06.196432Z","end":"2024-01-24T18:42:06.643934Z","steps":["trace[695113669] 'read index received'  (duration: 204.307397ms)","trace[695113669] 'applied index is now lower than readState.Index'  (duration: 243.189202ms)"],"step_count":2}
{"level":"info","ts":"2024-01-24T18:42:06.644223Z","caller":"traceutil/trace.go:171","msg":"trace[35181070] transaction","detail":"{read_only:false; response_revision:28864; number_of_response:1; }","duration":"617.779907ms","start":"2024-01-24T18:42:06.026405Z","end":"2024-01-24T18:42:06.644186Z","steps":["trace[35181070] 'process raft request'  (duration: 374.526524ms)","trace[35181070] 'compare'  (duration: 212.03926ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-24T18:42:06.644449Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:06.026334Z","time spent":"617.972017ms","remote":"127.0.0.1:40904","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":828,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14\" mod_revision:28573 > success:<request_put:<key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14\" value_size:743 lease:5991350167651666891 >> failure:<request_range:<key:\"/registry/events/default/prometheus-alertmanager-0.17ad54fce80aea14\" > >"}
{"level":"info","ts":"2024-01-24T18:42:06.646018Z","caller":"traceutil/trace.go:171","msg":"trace[1249635748] transaction","detail":"{read_only:false; response_revision:28865; number_of_response:1; }","duration":"596.85404ms","start":"2024-01-24T18:42:06.049114Z","end":"2024-01-24T18:42:06.645969Z","steps":["trace[1249635748] 'process raft request'  (duration: 594.517859ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:06.648269Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:06.049044Z","time spent":"599.036217ms","remote":"127.0.0.1:40932","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":5758,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/pods/default/prometheus-prometheus-node-exporter-q99rd\" mod_revision:26191 > success:<request_put:<key:\"/registry/pods/default/prometheus-prometheus-node-exporter-q99rd\" value_size:5686 >> failure:<request_range:<key:\"/registry/pods/default/prometheus-prometheus-node-exporter-q99rd\" > >"}
{"level":"warn","ts":"2024-01-24T18:42:06.647162Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"450.738007ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/endpointslices/default/kubernetes\" ","response":"range_response_count:1 size:478"}
{"level":"info","ts":"2024-01-24T18:42:06.64899Z","caller":"traceutil/trace.go:171","msg":"trace[948213940] range","detail":"{range_begin:/registry/endpointslices/default/kubernetes; range_end:; response_count:1; response_revision:28865; }","duration":"452.584445ms","start":"2024-01-24T18:42:06.196362Z","end":"2024-01-24T18:42:06.648947Z","steps":["trace[948213940] 'agreement among raft nodes before linearized reading'  (duration: 450.602404ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:06.649138Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:06.196329Z","time spent":"452.752319ms","remote":"127.0.0.1:40956","response type":"/etcdserverpb.KV/Range","request count":0,"request size":45,"response count":1,"response size":502,"request content":"key:\"/registry/endpointslices/default/kubernetes\" "}
{"level":"warn","ts":"2024-01-24T18:42:07.381167Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"456.243971ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350167651666911 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/endpointslices/default/kubernetes\" mod_revision:22275 > success:<request_put:<key:\"/registry/endpointslices/default/kubernetes\" value_size:376 >> failure:<request_range:<key:\"/registry/endpointslices/default/kubernetes\" > >>","response":"size:18"}
{"level":"info","ts":"2024-01-24T18:42:07.381439Z","caller":"traceutil/trace.go:171","msg":"trace[783935669] linearizableReadLoop","detail":"{readStateIndex:36331; appliedIndex:36330; }","duration":"702.090221ms","start":"2024-01-24T18:42:06.679302Z","end":"2024-01-24T18:42:07.381392Z","steps":["trace[783935669] 'read index received'  (duration: 245.135744ms)","trace[783935669] 'applied index is now lower than readState.Index'  (duration: 456.945886ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-24T18:42:07.382287Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"703.039297ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/kube-system/kube-apiserver-minikube\" ","response":"range_response_count:1 size:6596"}
{"level":"info","ts":"2024-01-24T18:42:07.382417Z","caller":"traceutil/trace.go:171","msg":"trace[73293549] range","detail":"{range_begin:/registry/pods/kube-system/kube-apiserver-minikube; range_end:; response_count:1; response_revision:28866; }","duration":"703.189852ms","start":"2024-01-24T18:42:06.679189Z","end":"2024-01-24T18:42:07.38238Z","steps":["trace[73293549] 'agreement among raft nodes before linearized reading'  (duration: 702.431054ms)"],"step_count":1}
{"level":"warn","ts":"2024-01-24T18:42:07.382758Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:06.679148Z","time spent":"703.554024ms","remote":"127.0.0.1:40932","response type":"/etcdserverpb.KV/Range","request count":0,"request size":52,"response count":1,"response size":6620,"request content":"key:\"/registry/pods/kube-system/kube-apiserver-minikube\" "}
{"level":"info","ts":"2024-01-24T18:42:07.405756Z","caller":"traceutil/trace.go:171","msg":"trace[1000375926] transaction","detail":"{read_only:false; response_revision:28866; number_of_response:1; }","duration":"726.977468ms","start":"2024-01-24T18:42:06.678713Z","end":"2024-01-24T18:42:07.405691Z","steps":["trace[1000375926] 'process raft request'  (duration: 245.967651ms)","trace[1000375926] 'compare'  (duration: 454.407999ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-24T18:42:07.406062Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:06.678649Z","time spent":"727.242979ms","remote":"127.0.0.1:40956","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":427,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/endpointslices/default/kubernetes\" mod_revision:22275 > success:<request_put:<key:\"/registry/endpointslices/default/kubernetes\" value_size:376 >> failure:<request_range:<key:\"/registry/endpointslices/default/kubernetes\" > >"}
{"level":"warn","ts":"2024-01-24T18:42:08.907156Z","caller":"etcdserver/util.go:170","msg":"apply request took too long","took":"549.42498ms","expected-duration":"100ms","prefix":"","request":"header:<ID:5991350167651666913 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" mod_revision:28854 > success:<request_put:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" value_size:600 >> failure:<request_range:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" > >>","response":"size:18"}
{"level":"info","ts":"2024-01-24T18:42:08.907349Z","caller":"traceutil/trace.go:171","msg":"trace[1833163919] transaction","detail":"{read_only:false; response_revision:28867; number_of_response:1; }","duration":"1.522339961s","start":"2024-01-24T18:42:07.384974Z","end":"2024-01-24T18:42:08.907316Z","steps":["trace[1833163919] 'process raft request'  (duration: 972.615171ms)","trace[1833163919] 'compare'  (duration: 548.126471ms)"],"step_count":2}
{"level":"warn","ts":"2024-01-24T18:42:08.907458Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2024-01-24T18:42:07.384846Z","time spent":"1.522556279s","remote":"127.0.0.1:40954","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":673,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" mod_revision:28854 > success:<request_put:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" value_size:600 >> failure:<request_range:<key:\"/registry/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii\" > >"}

* 
* ==> kernel <==
*  08:46:07 up 50 min,  0 users,  load average: 18.85, 19.64, 13.50
Linux minikube 5.10.57 #1 SMP Tue Nov 7 06:51:54 UTC 2023 x86_64 GNU/Linux
PRETTY_NAME="Buildroot 2021.02.12"

* 
* ==> kube-apiserver [687848787b26] <==
* E0131 08:42:59.173399       1 storage_rbac.go:232] unable to reconcile clusterrole.rbac.authorization.k8s.io/system:controller:root-ca-cert-publisher: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:controller:root-ca-cert-publisher": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.175702       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/cluster-admin: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/cluster-admin": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.176877       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:monitoring: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:monitoring": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.178344       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:discovery: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:discovery": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.179490       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:basic-user: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:basic-user": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.180510       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:public-info-viewer: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:public-info-viewer": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.181905       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:node-proxier: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:node-proxier": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.183185       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:kube-controller-manager: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:kube-controller-manager": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.184042       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:kube-dns: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:kube-dns": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.186720       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:kube-scheduler: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:kube-scheduler": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.188591       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:volume-scheduler: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:volume-scheduler": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.190170       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:node: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:node": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.191603       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:service-account-issuer-discovery: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:service-account-issuer-discovery": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.192888       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:attachdetach-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:attachdetach-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.194109       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:clusterrole-aggregation-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:clusterrole-aggregation-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.195478       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:cronjob-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:cronjob-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.196320       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:daemon-set-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:daemon-set-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.197585       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:deployment-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:deployment-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.198540       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:disruption-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:disruption-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.199625       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:endpoint-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:endpoint-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.200972       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:endpointslice-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:endpointslice-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.202494       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:endpointslicemirroring-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:endpointslicemirroring-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.203106       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:expand-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:expand-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.206039       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:ephemeral-volume-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:ephemeral-volume-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.207316       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:generic-garbage-collector: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:generic-garbage-collector": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.208602       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:horizontal-pod-autoscaler: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:horizontal-pod-autoscaler": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.209378       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:job-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:job-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.211782       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:namespace-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:namespace-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.213182       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:node-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:node-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.214477       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:persistent-volume-binder: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:persistent-volume-binder": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.215752       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:pod-garbage-collector: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:pod-garbage-collector": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.216992       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:replicaset-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:replicaset-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.218046       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:replication-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:replication-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.219102       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:resourcequota-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:resourcequota-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.220148       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:route-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:route-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.221286       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:service-account-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:service-account-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.222525       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:service-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:service-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.223482       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:statefulset-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:statefulset-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.224591       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:ttl-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:ttl-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.225649       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:certificate-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:certificate-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.226653       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:pvc-protection-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:pvc-protection-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.228874       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:pv-protection-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:pv-protection-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.229961       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:ttl-after-finished-controller: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:ttl-after-finished-controller": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.230884       1 storage_rbac.go:264] unable to reconcile clusterrolebinding.rbac.authorization.k8s.io/system:controller:root-ca-cert-publisher: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:controller:root-ca-cert-publisher": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.233130       1 storage_rbac.go:295] unable to reconcile role.rbac.authorization.k8s.io/system:controller:bootstrap-signer in kube-public: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-public/roles/system:controller:bootstrap-signer": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.234176       1 storage_rbac.go:295] unable to reconcile role.rbac.authorization.k8s.io/extension-apiserver-authentication-reader in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/extension-apiserver-authentication-reader": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.235262       1 storage_rbac.go:295] unable to reconcile role.rbac.authorization.k8s.io/system:controller:bootstrap-signer in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system:controller:bootstrap-signer": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.236188       1 storage_rbac.go:295] unable to reconcile role.rbac.authorization.k8s.io/system:controller:cloud-provider in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system:controller:cloud-provider": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.238316       1 storage_rbac.go:295] unable to reconcile role.rbac.authorization.k8s.io/system:controller:token-cleaner in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system:controller:token-cleaner": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.239185       1 storage_rbac.go:295] unable to reconcile role.rbac.authorization.k8s.io/system::leader-locking-kube-controller-manager in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system::leader-locking-kube-controller-manager": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.242108       1 storage_rbac.go:295] unable to reconcile role.rbac.authorization.k8s.io/system::leader-locking-kube-scheduler in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/roles/system::leader-locking-kube-scheduler": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.243205       1 storage_rbac.go:329] unable to reconcile rolebinding.rbac.authorization.k8s.io/system::extension-apiserver-authentication-reader in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system::extension-apiserver-authentication-reader": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.243892       1 storage_rbac.go:329] unable to reconcile rolebinding.rbac.authorization.k8s.io/system::leader-locking-kube-controller-manager in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system::leader-locking-kube-controller-manager": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.245982       1 storage_rbac.go:329] unable to reconcile rolebinding.rbac.authorization.k8s.io/system::leader-locking-kube-scheduler in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system::leader-locking-kube-scheduler": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.246792       1 storage_rbac.go:329] unable to reconcile rolebinding.rbac.authorization.k8s.io/system:controller:bootstrap-signer in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:controller:bootstrap-signer": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.248560       1 storage_rbac.go:329] unable to reconcile rolebinding.rbac.authorization.k8s.io/system:controller:cloud-provider in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:controller:cloud-provider": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.249175       1 storage_rbac.go:329] unable to reconcile rolebinding.rbac.authorization.k8s.io/system:controller:token-cleaner in kube-system: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:controller:token-cleaner": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.250872       1 storage_rbac.go:329] unable to reconcile rolebinding.rbac.authorization.k8s.io/system:controller:bootstrap-signer in kube-public: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-public/rolebindings/system:controller:bootstrap-signer": dial tcp 127.0.0.1:8443: connect: connection refused
E0131 08:42:59.252459       1 storage_rbac.go:187] unable to initialize clusterroles: Get "https://localhost:8443/apis/rbac.authorization.k8s.io/v1/clusterroles": dial tcp 127.0.0.1:8443: connect: connection refused
F0131 08:42:59.284669       1 hooks.go:203] PostStartHook "rbac/bootstrap-roles" failed: unable to initialize roles: timed out waiting for the condition

* 
* ==> kube-apiserver [d6d34f966d43] <==
* Trace[858836801]:  ---"Txn call completed" 810ms (08:45:58.582)]
Trace[858836801]: ---"Object stored in database" 811ms (08:45:58.582)
Trace[858836801]: [825.277792ms] [825.277792ms] END
I0131 08:45:59.447186       1 trace.go:236] Trace[727650507]: "GuaranteedUpdate etcd3" audit-id:,key:/masterleases/10.0.2.15,type:*v1.Endpoints,resource:apiServerIPInfo (31-Jan-2024 08:45:57.710) (total time: 1736ms):
Trace[727650507]: ---"Transaction prepared" 987ms (08:45:58.750)
Trace[727650507]: ---"Txn call completed" 696ms (08:45:59.447)
Trace[727650507]: [1.73648107s] [1.73648107s] END
I0131 08:45:59.464983       1 trace.go:236] Trace[1649876011]: "Patch" accept:application/vnd.kubernetes.protobuf, */*,audit-id:15d50ca0-096d-4d9e-88bb-147f7979972e,client:10.0.2.15,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events/metrics-server.17af620d9622ea74,user-agent:kube-controller-manager/v1.28.3 (linux/amd64) kubernetes/a8a1abc/system:serviceaccount:kube-system:endpoint-controller,verb:PATCH (31-Jan-2024 08:45:58.051) (total time: 1412ms):
Trace[1649876011]: ["GuaranteedUpdate etcd3" audit-id:15d50ca0-096d-4d9e-88bb-147f7979972e,key:/events/kube-system/metrics-server.17af620d9622ea74,type:*core.Event,resource:events 1412ms (08:45:58.052)
Trace[1649876011]:  ---"initial value restored" 517ms (08:45:58.569)
Trace[1649876011]:  ---"Txn call completed" 890ms (08:45:59.464)]
Trace[1649876011]: ---"Object stored in database" 892ms (08:45:59.464)
Trace[1649876011]: [1.41297806s] [1.41297806s] END
I0131 08:45:59.475500       1 trace.go:236] Trace[1808903876]: "Patch" accept:application/vnd.kubernetes.protobuf,application/json,audit-id:26d049d9-ea5c-4283-ad6f-05e612944cd5,client:10.0.2.15,protocol:HTTP/2.0,resource:pods,scope:resource,url:/api/v1/namespaces/kube-system/pods/metrics-server-7c66d45ddc-p79c5/status,user-agent:kubelet/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PATCH (31-Jan-2024 08:45:58.592) (total time: 881ms):
Trace[1808903876]: ["GuaranteedUpdate etcd3" audit-id:26d049d9-ea5c-4283-ad6f-05e612944cd5,key:/pods/kube-system/metrics-server-7c66d45ddc-p79c5,type:*core.Pod,resource:pods 880ms (08:45:58.593)
Trace[1808903876]:  ---"Txn call completed" 859ms (08:45:59.468)]
Trace[1808903876]: ---"Object stored in database" 861ms (08:45:59.468)
Trace[1808903876]: [881.055242ms] [881.055242ms] END
I0131 08:46:00.635988       1 trace.go:236] Trace[1801404525]: "Patch" accept:application/vnd.kubernetes.protobuf, */*,audit-id:9054f55e-9605-4b90-865c-92013514c69f,client:10.0.2.15,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events/metrics-server.17af620d9622ea74,user-agent:kube-controller-manager/v1.28.3 (linux/amd64) kubernetes/a8a1abc/system:serviceaccount:kube-system:endpoint-controller,verb:PATCH (31-Jan-2024 08:45:59.802) (total time: 833ms):
Trace[1801404525]: ["GuaranteedUpdate etcd3" audit-id:9054f55e-9605-4b90-865c-92013514c69f,key:/events/kube-system/metrics-server.17af620d9622ea74,type:*core.Event,resource:events 833ms (08:45:59.802)
Trace[1801404525]:  ---"Txn call completed" 811ms (08:46:00.635)]
Trace[1801404525]: ---"Object stored in database" 812ms (08:46:00.635)
Trace[1801404525]: [833.466297ms] [833.466297ms] END
I0131 08:46:03.627010       1 trace.go:236] Trace[273839874]: "Patch" accept:application/vnd.kubernetes.protobuf, */*,audit-id:faa91049-4ba0-49d1-93b3-c25bcb85e8f6,client:10.0.2.15,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events/metrics-server.17af620d9622ea74,user-agent:kube-controller-manager/v1.28.3 (linux/amd64) kubernetes/a8a1abc/system:serviceaccount:kube-system:endpoint-controller,verb:PATCH (31-Jan-2024 08:46:00.643) (total time: 2983ms):
Trace[273839874]: ["GuaranteedUpdate etcd3" audit-id:faa91049-4ba0-49d1-93b3-c25bcb85e8f6,key:/events/kube-system/metrics-server.17af620d9622ea74,type:*core.Event,resource:events 2982ms (08:46:00.644)
Trace[273839874]:  ---"Txn call completed" 2972ms (08:46:03.626)]
Trace[273839874]: ---"Object stored in database" 2976ms (08:46:03.626)
Trace[273839874]: [2.983149321s] [2.983149321s] END
I0131 08:46:03.628345       1 trace.go:236] Trace[1279380561]: "Get" accept:application/json, */*,audit-id:a153460c-b1e4-49d9-aa23-4c3ff6468e94,client:10.0.2.15,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:GET (31-Jan-2024 08:46:00.657) (total time: 2970ms):
Trace[1279380561]: ---"About to write a response" 2970ms (08:46:03.628)
Trace[1279380561]: [2.970569497s] [2.970569497s] END
I0131 08:46:04.485151       1 trace.go:236] Trace[1996147132]: "Update" accept:application/json, */*,audit-id:59801142-1e13-467b-b5cd-5e695d7c1baf,client:10.0.2.15,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (31-Jan-2024 08:46:03.634) (total time: 850ms):
Trace[1996147132]: ["GuaranteedUpdate etcd3" audit-id:59801142-1e13-467b-b5cd-5e695d7c1baf,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 849ms (08:46:03.635)
Trace[1996147132]:  ---"Txn call completed" 846ms (08:46:04.484)]
Trace[1996147132]: [850.082384ms] [850.082384ms] END
I0131 08:46:04.686271       1 trace.go:236] Trace[1652424892]: "List" accept:application/json, */*,audit-id:7bc0fdc2-2b6f-4218-a50e-eb99bc9d77b9,client:127.0.0.1,protocol:HTTP/2.0,resource:events,scope:cluster,url:/api/v1/events,user-agent:kubectl/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:LIST (31-Jan-2024 08:45:59.651) (total time: 5034ms):
Trace[1652424892]: ["List(recursive=true) etcd3" audit-id:7bc0fdc2-2b6f-4218-a50e-eb99bc9d77b9,key:/events,resourceVersion:,resourceVersionMatch:,limit:500,continue: 4857ms (08:45:59.828)]
Trace[1652424892]: [5.0341727s] [5.0341727s] END
I0131 08:46:04.875204       1 trace.go:236] Trace[1015973399]: "Patch" accept:application/vnd.kubernetes.protobuf, */*,audit-id:e022b590-d81f-41db-8886-4a4c6952f74a,client:10.0.2.15,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events/metrics-server.17af620d9622ea74,user-agent:kube-controller-manager/v1.28.3 (linux/amd64) kubernetes/a8a1abc/system:serviceaccount:kube-system:endpoint-controller,verb:PATCH (31-Jan-2024 08:46:03.639) (total time: 1235ms):
Trace[1015973399]: ["GuaranteedUpdate etcd3" audit-id:e022b590-d81f-41db-8886-4a4c6952f74a,key:/events/kube-system/metrics-server.17af620d9622ea74,type:*core.Event,resource:events 1235ms (08:46:03.640)
Trace[1015973399]:  ---"initial value restored" 854ms (08:46:04.494)
Trace[1015973399]:  ---"Txn call completed" 375ms (08:46:04.874)]
Trace[1015973399]: ---"Object stored in database" 377ms (08:46:04.874)
Trace[1015973399]: [1.235171592s] [1.235171592s] END
I0131 08:46:06.277342       1 trace.go:236] Trace[62885314]: "Create" accept:application/vnd.kubernetes.protobuf, */*,audit-id:fc64065c-1e7b-493d-9370-cca3edc3c791,client:10.0.2.15,protocol:HTTP/2.0,resource:events,scope:resource,url:/api/v1/namespaces/kube-system/events,user-agent:kube-controller-manager/v1.28.3 (linux/amd64) kubernetes/a8a1abc/system:serviceaccount:kube-system:endpoint-controller,verb:POST (31-Jan-2024 08:46:05.330) (total time: 946ms):
Trace[62885314]: ["Create etcd3" audit-id:fc64065c-1e7b-493d-9370-cca3edc3c791,key:/events/kube-system/metrics-server.17af621377bee397,type:*core.Event,resource:events 944ms (08:46:05.332)
Trace[62885314]:  ---"Txn call succeeded" 943ms (08:46:06.276)]
Trace[62885314]: [946.214849ms] [946.214849ms] END
I0131 08:46:07.351918       1 trace.go:236] Trace[1500416298]: "Update" accept:application/vnd.kubernetes.protobuf, */*,audit-id:fe4eed11-eb43-44ce-b998-269eb10f5d6f,client:127.0.0.1,protocol:HTTP/2.0,resource:leases,scope:resource,url:/apis/coordination.k8s.io/v1/namespaces/kube-system/leases/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,user-agent:kube-apiserver/v1.28.3 (linux/amd64) kubernetes/a8a1abc,verb:PUT (31-Jan-2024 08:46:06.745) (total time: 605ms):
Trace[1500416298]: ["GuaranteedUpdate etcd3" audit-id:fe4eed11-eb43-44ce-b998-269eb10f5d6f,key:/leases/kube-system/apiserver-eqt674mfxb4j56mrjjkoe7b7ii,type:*coordination.Lease,resource:leases.coordination.k8s.io 605ms (08:46:06.746)
Trace[1500416298]:  ---"Txn call completed" 603ms (08:46:07.351)]
Trace[1500416298]: [605.965833ms] [605.965833ms] END
I0131 08:46:07.353814       1 trace.go:236] Trace[1431111427]: "Update" accept:application/json, */*,audit-id:6646360e-9383-451b-a191-df5d21c3072b,client:10.0.2.15,protocol:HTTP/2.0,resource:endpoints,scope:resource,url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,verb:PUT (31-Jan-2024 08:46:06.677) (total time: 676ms):
Trace[1431111427]: ["GuaranteedUpdate etcd3" audit-id:6646360e-9383-451b-a191-df5d21c3072b,key:/services/endpoints/kube-system/k8s.io-minikube-hostpath,type:*core.Endpoints,resource:endpoints 675ms (08:46:06.678)
Trace[1431111427]:  ---"Txn call completed" 672ms (08:46:07.352)]
Trace[1431111427]: [676.052928ms] [676.052928ms] END
I0131 08:46:08.483655       1 trace.go:236] Trace[1825739990]: "GuaranteedUpdate etcd3" audit-id:,key:/masterleases/10.0.2.15,type:*v1.Endpoints,resource:apiServerIPInfo (31-Jan-2024 08:46:07.710) (total time: 773ms):
Trace[1825739990]: ---"Transaction prepared" 561ms (08:46:08.282)
Trace[1825739990]: ---"Txn call completed" 200ms (08:46:08.483)
Trace[1825739990]: [773.344576ms] [773.344576ms] END

* 
* ==> kube-controller-manager [5864505bbbcb] <==
* I0131 08:00:25.656193       1 serving.go:348] Generated self-signed cert in-memory
I0131 08:00:26.857659       1 controllermanager.go:189] "Starting" version="v1.28.3"
I0131 08:00:26.857739       1 controllermanager.go:191] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0131 08:00:26.899426       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0131 08:00:26.900383       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0131 08:00:26.905333       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0131 08:00:26.905874       1 secure_serving.go:213] Serving securely on 127.0.0.1:10257
E0131 08:00:43.209554       1 controllermanager.go:235] "Error building controller context" err="failed to wait for apiserver being healthy: timed out waiting for the condition: failed to get apiserver /healthz status: an error on the server (\"[+]ping ok\\n[+]log ok\\n[+]etcd ok\\n[+]poststarthook/start-kube-apiserver-admission-initializer ok\\n[+]poststarthook/generic-apiserver-start-informers ok\\n[+]poststarthook/priority-and-fairness-config-consumer ok\\n[+]poststarthook/priority-and-fairness-filter ok\\n[+]poststarthook/storage-object-count-tracker-hook ok\\n[+]poststarthook/start-apiextensions-informers ok\\n[+]poststarthook/start-apiextensions-controllers ok\\n[+]poststarthook/crd-informer-synced ok\\n[+]poststarthook/start-service-ip-repair-controllers ok\\n[-]poststarthook/rbac/bootstrap-roles failed: reason withheld\\n[+]poststarthook/scheduling/bootstrap-system-priority-classes ok\\n[+]poststarthook/priority-and-fairness-config-producer ok\\n[+]poststarthook/start-system-namespaces-controller ok\\n[+]poststarthook/bootstrap-controller ok\\n[+]poststarthook/start-cluster-authentication-info-controller ok\\n[+]poststarthook/start-kube-apiserver-identity-lease-controller ok\\n[+]poststarthook/start-deprecated-kube-apiserver-identity-lease-garbage-collector ok\\n[+]poststarthook/start-kube-apiserver-identity-lease-garbage-collector ok\\n[+]poststarthook/start-legacy-token-tracking-controller ok\\n[+]poststarthook/aggregator-reload-proxy-client-cert ok\\n[+]poststarthook/start-kube-aggregator-informers ok\\n[+]poststarthook/apiservice-registration-controller ok\\n[+]poststarthook/apiservice-status-available-controller ok\\n[+]poststarthook/kube-apiserver-autoregistration ok\\n[+]autoregister-completion ok\\n[+]poststarthook/apiservice-openapi-controller ok\\n[+]poststarthook/apiservice-openapiv3-controller ok\\n[+]poststarthook/apiservice-discovery-controller ok\\nhealthz check failed\") has prevented the request from succeeding"

* 
* ==> kube-controller-manager [d56ac6d5a414] <==
* E0131 08:43:44.131716       1 resource_quota_controller.go:440] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1
I0131 08:43:44.437480       1 event.go:307] "Event occurred" object="default/prometheus-prometheus-pushgateway-6ccd698d79-lxh6g" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0131 08:43:45.399367       1 event.go:307] "Event occurred" object="kubernetes-dashboard/dashboard-metrics-scraper-7fd5cb4ddc-dltn7" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0131 08:43:46.444825       1 controller_utils.go:151] "Failed to update status for pod" pod="kubernetes-dashboard/kubernetes-dashboard-8694d4445c-z4ghh" err="Operation cannot be fulfilled on pods \"kubernetes-dashboard-8694d4445c-z4ghh\": the object has been modified; please apply your changes to the latest version and try again"
I0131 08:43:46.463573       1 event.go:307] "Event occurred" object="kubernetes-dashboard/kubernetes-dashboard-8694d4445c-z4ghh" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0131 08:43:50.860544       1 event.go:307] "Event occurred" object="kube-system/kube-controller-manager-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0131 08:43:53.670313       1 trace.go:236] Trace[1148604880]: "DeltaFIFO Pop Process" ID:default/prometheus-prometheus-pushgateway-6ccd698d79-lxh6g,Depth:11,Reason:slow event handlers blocking the queue (31-Jan-2024 08:43:52.931) (total time: 738ms):
Trace[1148604880]: [738.803893ms] [738.803893ms] END
I0131 08:43:57.564917       1 event.go:307] "Event occurred" object="kube-system/metrics-server" fieldPath="" kind="Endpoints" apiVersion="v1" type="Warning" reason="FailedToUpdateEndpoint" message="Failed to update endpoint kube-system/metrics-server: etcdserver: request timed out"
E0131 08:43:58.052971       1 event.go:280] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"prometheus-kube-state-metrics.17af61c6fe8cb7e6", GenerateName:"", Namespace:"default", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Service", Namespace:"default", Name:"prometheus-kube-state-metrics", UID:"ff5e971d-d3da-4e1f-9105-5e20f7bd211a", APIVersion:"v1", ResourceVersion:"17246", FieldPath:""}, Reason:"FailedToUpdateEndpointSlices", Message:"Error updating Endpoint Slices for Service default/prometheus-kube-state-metrics: failed to update prometheus-kube-state-metrics-rz9tv EndpointSlice for Service default/prometheus-kube-state-metrics: Put \"https://10.0.2.15:8443/apis/discovery.k8s.io/v1/namespaces/default/endpointslices/prometheus-kube-state-metrics-rz9tv\": dial tcp 10.0.2.15:8443: connect: connection refused", Source:v1.EventSource{Component:"endpoint-slice-controller", Host:""}, FirstTimestamp:time.Date(2024, time.January, 31, 8, 38, 11, 98761190, time.Local), LastTimestamp:time.Date(2024, time.January, 31, 8, 38, 11, 98761190, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"endpoint-slice-controller", ReportingInstance:""}': 'etcdserver: request timed out' (will not retry!)
E0131 08:43:58.053909       1 event.go:280] Server rejected event '&v1.Event{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"kubernetes-dashboard-8694d4445c-z4ghh.17af620dfa5010ce", GenerateName:"", Namespace:"kubernetes-dashboard", SelfLink:"", UID:"", ResourceVersion:"", Generation:0, CreationTimestamp:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string(nil), Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry(nil)}, InvolvedObject:v1.ObjectReference{Kind:"Pod", Namespace:"kubernetes-dashboard", Name:"kubernetes-dashboard-8694d4445c-z4ghh", UID:"09c87280-9b02-434e-bb80-093807bc6281", APIVersion:"v1", ResourceVersion:"29403", FieldPath:""}, Reason:"NodeNotReady", Message:"Node is not ready", Source:v1.EventSource{Component:"node-controller", Host:""}, FirstTimestamp:time.Date(2024, time.January, 31, 8, 43, 15, 970355406, time.Local), LastTimestamp:time.Date(2024, time.January, 31, 8, 43, 15, 970355406, time.Local), Count:1, Type:"Warning", EventTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Series:(*v1.EventSeries)(nil), Action:"", Related:(*v1.ObjectReference)(nil), ReportingController:"node-controller", ReportingInstance:""}': 'etcdserver: request timed out' (will not retry!)
I0131 08:43:58.286339       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-prometheus-pushgateway-6ccd698d79" duration="5.354764315s"
I0131 08:43:58.302409       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="4.616983937s"
I0131 08:43:58.305721       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-server-bc7ccb595" duration="4.621936032s"
I0131 08:43:58.454359       1 event.go:307] "Event occurred" object="kube-system/kube-proxy-djm5l" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0131 08:43:58.464087       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/dashboard-metrics-scraper-7fd5cb4ddc" duration="3.541878501s"
I0131 08:43:58.527903       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-8694d4445c" duration="3.312721171s"
I0131 08:43:59.564932       1 event.go:307] "Event occurred" object="kube-system/kube-scheduler-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0131 08:44:01.306457       1 controller_utils.go:151] "Failed to update status for pod" pod="kube-system/etcd-minikube" err="Operation cannot be fulfilled on pods \"etcd-minikube\": the object has been modified; please apply your changes to the latest version and try again"
I0131 08:44:01.345692       1 event.go:307] "Event occurred" object="kube-system/etcd-minikube" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0131 08:44:01.759939       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-kube-state-metrics-745b475957" duration="2.289723884s"
I0131 08:44:01.765851       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/books-app-deployment-5c866bfb66" duration="182.418µs"
I0131 08:44:01.792144       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-kube-state-metrics-745b475957" duration="270.399µs"
I0131 08:44:02.320375       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-prometheus-pushgateway-6ccd698d79" duration="239.764µs"
I0131 08:44:02.614915       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/dashboard-metrics-scraper-7fd5cb4ddc" duration="768.679µs"
I0131 08:44:02.622475       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-8694d4445c" duration="3.843672ms"
I0131 08:44:02.659542       1 controller_utils.go:151] "Failed to update status for pod" pod="kube-system/storage-provisioner" err="Operation cannot be fulfilled on pods \"storage-provisioner\": the object has been modified; please apply your changes to the latest version and try again"
E0131 08:44:02.659793       1 node_lifecycle_controller.go:751] unable to mark all pods NotReady on node minikube: [pods "prometheus-alertmanager-0" is forbidden: User "system:serviceaccount:kube-system:node-controller" cannot update resource "pods/status" in API group "" in the namespace "default", Operation cannot be fulfilled on pods "kubernetes-dashboard-8694d4445c-z4ghh": the object has been modified; please apply your changes to the latest version and try again, Operation cannot be fulfilled on pods "etcd-minikube": the object has been modified; please apply your changes to the latest version and try again, Operation cannot be fulfilled on pods "storage-provisioner": the object has been modified; please apply your changes to the latest version and try again]; queuing for retry
I0131 08:44:02.665503       1 event.go:307] "Event occurred" object="kube-system/storage-provisioner" fieldPath="" kind="Pod" apiVersion="v1" type="Warning" reason="NodeNotReady" message="Node is not ready"
I0131 08:44:03.034680       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="3.520989829s"
I0131 08:44:03.067075       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-server-bc7ccb595" duration="3.734225881s"
I0131 08:44:03.070808       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-server-bc7ccb595" duration="258.519µs"
I0131 08:44:04.188916       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-kube-state-metrics-745b475957" duration="1.011278ms"
I0131 08:44:04.239952       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="1.205131486s"
I0131 08:44:04.245596       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="5.464236ms"
I0131 08:44:05.269748       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-7c66d45ddc" duration="2.948643893s"
I0131 08:44:05.280917       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-7c66d45ddc" duration="11.024609ms"
I0131 08:44:06.595088       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-server-bc7ccb595" duration="681.810016ms"
I0131 08:44:06.597480       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-server-bc7ccb595" duration="152.9µs"
I0131 08:44:07.752148       1 node_lifecycle_controller.go:1048] "Controller detected that some Nodes are Ready. Exiting master disruption mode"
I0131 08:44:12.190441       1 garbagecollector.go:816] "failed to discover some groups" groups="<internal error: json: unsupported type: map[schema.GroupVersion]error>"
I0131 08:44:12.765665       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-kube-state-metrics-745b475957" duration="163.124µs"
E0131 08:44:14.151593       1 resource_quota_controller.go:440] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1
I0131 08:44:26.775142       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-prometheus-pushgateway-6ccd698d79" duration="6.851345341s"
I0131 08:44:26.775576       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-prometheus-pushgateway-6ccd698d79" duration="245.906µs"
I0131 08:44:30.517815       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/dashboard-metrics-scraper-7fd5cb4ddc" duration="1.891264363s"
I0131 08:44:31.337922       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/dashboard-metrics-scraper-7fd5cb4ddc" duration="178.989µs"
I0131 08:44:35.749937       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-8694d4445c" duration="1.161694402s"
I0131 08:44:35.750806       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-8694d4445c" duration="231.814µs"
I0131 08:44:42.526832       1 garbagecollector.go:816] "failed to discover some groups" groups="<internal error: json: unsupported type: map[schema.GroupVersion]error>"
I0131 08:44:43.605937       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-kube-state-metrics-745b475957" duration="191.667µs"
E0131 08:44:44.174663       1 resource_quota_controller.go:440] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1
I0131 08:45:04.053955       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-7c66d45ddc" duration="194.677µs"
I0131 08:45:05.397781       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kubernetes-dashboard/kubernetes-dashboard-8694d4445c" duration="807.02µs"
I0131 08:45:12.569628       1 garbagecollector.go:816] "failed to discover some groups" groups="<internal error: json: unsupported type: map[schema.GroupVersion]error>"
E0131 08:45:14.213814       1 resource_quota_controller.go:440] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1
I0131 08:45:42.614015       1 garbagecollector.go:816] "failed to discover some groups" groups="<internal error: json: unsupported type: map[schema.GroupVersion]error>"
E0131 08:45:44.268520       1 resource_quota_controller.go:440] unable to retrieve the complete list of server APIs: metrics.k8s.io/v1beta1: stale GroupVersion discovery: metrics.k8s.io/v1beta1
I0131 08:45:50.016738       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="default/prometheus-kube-state-metrics-745b475957" duration="246.448µs"
I0131 08:45:59.492890       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/metrics-server-7c66d45ddc" duration="1.297686ms"

* 
* ==> kube-proxy [67a74ce18974] <==
* I0131 08:03:14.925701       1 server_others.go:69] "Using iptables proxy"
I0131 08:03:33.642855       1 node.go:141] Successfully retrieved node IP: 10.0.2.15
I0131 08:03:50.294925       1 server_others.go:121] "No iptables support for family" ipFamily="IPv6"
I0131 08:03:50.895951       1 server.go:634] "kube-proxy running in single-stack mode" ipFamily="IPv4"
I0131 08:03:50.901850       1 server_others.go:152] "Using iptables Proxier"
I0131 08:03:50.901941       1 proxier.go:251] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0131 08:03:51.513299       1 server.go:846] "Version info" version="v1.28.3"
I0131 08:03:51.514112       1 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0131 08:03:54.536821       1 config.go:97] "Starting endpoint slice config controller"
I0131 08:03:54.536906       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0131 08:03:54.536994       1 config.go:188] "Starting service config controller"
I0131 08:03:54.537022       1 shared_informer.go:311] Waiting for caches to sync for service config
I0131 08:03:54.957373       1 config.go:315] "Starting node config controller"
I0131 08:03:54.959012       1 shared_informer.go:311] Waiting for caches to sync for node config
I0131 08:03:59.863110       1 shared_informer.go:318] Caches are synced for endpoint slice config
I0131 08:04:00.392072       1 shared_informer.go:318] Caches are synced for node config
I0131 08:04:01.923107       1 shared_informer.go:318] Caches are synced for service config
I0131 08:04:07.402046       1 trace.go:236] Trace[1567221927]: "iptables restore" (31-Jan-2024 08:04:02.557) (total time: 4844ms):
Trace[1567221927]: [4.844061344s] [4.844061344s] END
I0131 08:06:38.941772       1 trace.go:236] Trace[761548155]: "iptables save" (31-Jan-2024 08:06:36.889) (total time: 2052ms):
Trace[761548155]: [2.05260973s] [2.05260973s] END
I0131 08:41:50.396287       1 trace.go:236] Trace[922695864]: "iptables ChainExists" (31-Jan-2024 08:41:23.550) (total time: 21889ms):
Trace[922695864]: [21.889376714s] [21.889376714s] END
I0131 08:42:55.795508       1 trace.go:236] Trace[406217786]: "iptables ChainExists" (31-Jan-2024 08:42:51.855) (total time: 3939ms):
Trace[406217786]: [3.939844927s] [3.939844927s] END
I0131 08:43:01.402759       1 trace.go:236] Trace[433896466]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (31-Jan-2024 08:42:42.560) (total time: 18451ms):
Trace[433896466]: ---"Objects listed" error:<nil> 17667ms (08:43:00.227)
Trace[433896466]: [18.451095823s] [18.451095823s] END
I0131 08:43:01.662165       1 trace.go:236] Trace[858814699]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (31-Jan-2024 08:42:45.932) (total time: 15729ms):
Trace[858814699]: ---"Objects listed" error:<nil> 13503ms (08:42:59.436)
Trace[858814699]: ---"Objects extracted" 2225ms (08:43:01.661)
Trace[858814699]: [15.729132259s] [15.729132259s] END
I0131 08:43:01.756820       1 trace.go:236] Trace[1749207439]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (31-Jan-2024 08:42:42.560) (total time: 18286ms):
Trace[1749207439]: ---"Objects listed" error:<nil> 18286ms (08:43:00.847)
Trace[1749207439]: [18.286658916s] [18.286658916s] END
I0131 08:43:09.043551       1 trace.go:236] Trace[2084828511]: "iptables save" (31-Jan-2024 08:43:04.228) (total time: 4814ms):
Trace[2084828511]: [4.814656891s] [4.814656891s] END
I0131 08:44:26.151509       1 trace.go:236] Trace[2144983210]: "iptables ChainExists" (31-Jan-2024 08:44:21.022) (total time: 2087ms):
Trace[2144983210]: [2.087969599s] [2.087969599s] END

* 
* ==> kube-proxy [b981f27ddb8e] <==
* Trace[1458440778]: [2.245815877s] [2.245815877s] END
W0124 17:13:53.850600       1 reflector.go:458] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0124 17:13:53.850863       1 reflector.go:458] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0124 17:13:53.851023       1 reflector.go:458] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0124 17:14:04.739359       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25341": net/http: TLS handshake timeout
I0124 17:14:04.739768       1 trace.go:236] Trace[481290683]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:13:54.719) (total time: 10020ms):
Trace[481290683]: ---"Objects listed" error:Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25341": net/http: TLS handshake timeout 10020ms (17:14:04.739)
Trace[481290683]: [10.020528042s] [10.020528042s] END
E0124 17:14:04.739843       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25341": net/http: TLS handshake timeout
W0124 17:14:04.797255       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&resourceVersion=25427": net/http: TLS handshake timeout
I0124 17:14:04.797615       1 trace.go:236] Trace[1320173021]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:13:54.784) (total time: 10013ms):
Trace[1320173021]: ---"Objects listed" error:Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&resourceVersion=25427": net/http: TLS handshake timeout 10012ms (17:14:04.797)
Trace[1320173021]: [10.013195353s] [10.013195353s] END
E0124 17:14:04.797696       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&resourceVersion=25427": net/http: TLS handshake timeout
W0124 17:14:05.351851       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25440": net/http: TLS handshake timeout
I0124 17:14:05.352182       1 trace.go:236] Trace[299082004]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:13:55.295) (total time: 10056ms):
Trace[299082004]: ---"Objects listed" error:Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25440": net/http: TLS handshake timeout 10056ms (17:14:05.351)
Trace[299082004]: [10.056218409s] [10.056218409s] END
E0124 17:14:05.352254       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25440": net/http: TLS handshake timeout
W0124 17:14:17.030939       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&resourceVersion=25427": net/http: TLS handshake timeout
I0124 17:14:17.031071       1 trace.go:236] Trace[1555500172]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:07.022) (total time: 10008ms):
Trace[1555500172]: ---"Objects listed" error:Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&resourceVersion=25427": net/http: TLS handshake timeout 10008ms (17:14:17.030)
Trace[1555500172]: [10.008964142s] [10.008964142s] END
E0124 17:14:17.031107       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://control-plane.minikube.internal:8443/api/v1/nodes?fieldSelector=metadata.name%!D(MISSING)minikube&resourceVersion=25427": net/http: TLS handshake timeout
W0124 17:14:17.031343       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25440": net/http: TLS handshake timeout
I0124 17:14:17.106226       1 trace.go:236] Trace[1161079018]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:07.024) (total time: 10081ms):
Trace[1161079018]: ---"Objects listed" error:Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25440": net/http: TLS handshake timeout 10007ms (17:14:17.031)
Trace[1161079018]: [10.081755631s] [10.081755631s] END
E0124 17:14:17.106587       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.EndpointSlice: failed to list *v1.EndpointSlice: Get "https://control-plane.minikube.internal:8443/apis/discovery.k8s.io/v1/endpointslices?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25440": net/http: TLS handshake timeout
W0124 17:14:17.479474       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25341": net/http: TLS handshake timeout
I0124 17:14:17.479830       1 trace.go:236] Trace[2101207458]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:07.270) (total time: 10208ms):
Trace[2101207458]: ---"Objects listed" error:Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25341": net/http: TLS handshake timeout 10208ms (17:14:17.479)
Trace[2101207458]: [10.208963019s] [10.208963019s] END
E0124 17:14:17.479912       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://control-plane.minikube.internal:8443/api/v1/services?labelSelector=%!s(MISSING)ervice.kubernetes.io%!F(MISSING)headless%!C(MISSING)%!s(MISSING)ervice.kubernetes.io%!F(MISSING)service-proxy-name&resourceVersion=25341": net/http: TLS handshake timeout
I0124 17:14:34.513511       1 trace.go:236] Trace[1816299144]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:21.845) (total time: 12668ms):
Trace[1816299144]: ---"Objects listed" error:<nil> 12667ms (17:14:34.512)
Trace[1816299144]: [12.668110253s] [12.668110253s] END
I0124 17:14:34.545721       1 trace.go:236] Trace[1984481052]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:20.994) (total time: 13524ms):
Trace[1984481052]: ---"Objects listed" error:<nil> 13524ms (17:14:34.518)
Trace[1984481052]: [13.524300232s] [13.524300232s] END
I0124 17:14:41.341924       1 trace.go:236] Trace[1769552337]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:21.260) (total time: 20081ms):
Trace[1769552337]: ---"Objects listed" error:<nil> 20081ms (17:14:41.341)
Trace[1769552337]: [20.081634366s] [20.081634366s] END
I0124 17:15:13.174033       1 trace.go:236] Trace[1571702536]: "iptables ChainExists" (24-Jan-2024 17:15:08.788) (total time: 4384ms):
Trace[1571702536]: [4.384874742s] [4.384874742s] END
W0124 17:23:29.670916       1 reflector.go:458] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.Node ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0124 17:23:29.671159       1 reflector.go:458] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.EndpointSlice ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
W0124 17:23:29.671218       1 reflector.go:458] vendor/k8s.io/client-go/informers/factory.go:150: watch of *v1.Service ended with: an error on the server ("unable to decode an event from the watch stream: http2: client connection lost") has prevented the request from succeeding
I0124 17:26:20.059593       1 trace.go:236] Trace[1314718159]: "iptables save" (24-Jan-2024 17:26:11.320) (total time: 2218ms):
Trace[1314718159]: [2.218950039s] [2.218950039s] END
I0124 17:26:50.030910       1 trace.go:236] Trace[1389810307]: "iptables ChainExists" (24-Jan-2024 17:26:38.131) (total time: 11895ms):
Trace[1389810307]: [11.895457151s] [11.895457151s] END
I0124 17:30:40.542859       1 trace.go:236] Trace[1186490025]: "iptables ChainExists" (24-Jan-2024 17:30:38.118) (total time: 2424ms):
Trace[1186490025]: [2.424317174s] [2.424317174s] END
I0124 18:33:05.700315       1 trace.go:236] Trace[1641517521]: "iptables save" (24-Jan-2024 18:32:59.561) (total time: 4569ms):
Trace[1641517521]: [4.569204625s] [4.569204625s] END
I0124 18:33:42.528099       1 trace.go:236] Trace[1178646883]: "iptables ChainExists" (24-Jan-2024 18:33:38.658) (total time: 3869ms):
Trace[1178646883]: [3.869487427s] [3.869487427s] END
I0124 18:34:44.240658       1 trace.go:236] Trace[1967169945]: "iptables ChainExists" (24-Jan-2024 18:34:38.509) (total time: 5730ms):
Trace[1967169945]: [5.730784344s] [5.730784344s] END

* 
* ==> kube-scheduler [95474da4beb7] <==
* Trace[199148015]: ---"Objects listed" error:Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused 21586ms (08:43:04.693)
Trace[199148015]: [22.61031368s] [22.61031368s] END
E0131 08:43:05.717562       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
I0131 08:43:05.717679       1 trace.go:236] Trace[1307378685]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (31-Jan-2024 08:42:47.430) (total time: 17263ms):
Trace[1307378685]: ---"Objects listed" error:Get "https://10.0.2.15:8443/apis/policy/v1/poddisruptionbudgets?resourceVersion=30875": write tcp 10.0.2.15:50592->10.0.2.15:8443: write: broken pipe 16405ms (08:43:03.836)
Trace[1307378685]: [17.263087832s] [17.263087832s] END
E0131 08:43:05.717743       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://10.0.2.15:8443/apis/policy/v1/poddisruptionbudgets?resourceVersion=30875": write tcp 10.0.2.15:50592->10.0.2.15:8443: write: broken pipe
W0131 08:43:06.062417       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused
I0131 08:43:06.062617       1 trace.go:236] Trace[1375836112]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (31-Jan-2024 08:42:46.144) (total time: 19918ms):
Trace[1375836112]: ---"Objects listed" error:Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused 19918ms (08:43:06.062)
Trace[1375836112]: [19.918129427s] [19.918129427s] END
E0131 08:43:06.102634       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://10.0.2.15:8443/api/v1/replicationcontrollers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
I0131 08:43:06.103305       1 trace.go:236] Trace[1155449366]: "DeltaFIFO Pop Process" ID:default/prometheus-kube-state-metrics-745b475957-k9mgr,Depth:13,Reason:slow event handlers blocking the queue (31-Jan-2024 08:43:05.713) (total time: 389ms):
Trace[1155449366]: [389.912133ms] [389.912133ms] END
I0131 08:43:06.162663       1 trace.go:236] Trace[973907015]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (31-Jan-2024 08:42:52.584) (total time: 13578ms):
Trace[973907015]: ---"Objects listed" error:<nil> 13578ms (08:43:06.162)
Trace[973907015]: [13.57839915s] [13.57839915s] END
E0131 08:43:06.062665       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:08.034070       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://10.0.2.15:8443/api/v1/replicationcontrollers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:08.034395       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://10.0.2.15:8443/api/v1/replicationcontrollers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:08.151948       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://10.0.2.15:8443/apis/policy/v1/poddisruptionbudgets?resourceVersion=30875": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:08.152126       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://10.0.2.15:8443/apis/policy/v1/poddisruptionbudgets?resourceVersion=30875": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:08.597807       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:08.597958       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:08.686048       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:08.686152       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:10.323591       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=30858": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:10.323818       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=30858": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:11.945765       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://10.0.2.15:8443/api/v1/replicationcontrollers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:11.945921       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://10.0.2.15:8443/api/v1/replicationcontrollers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:12.370013       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=30858": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:12.370205       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=30858": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:12.445066       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:12.445368       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:13.710825       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:13.711060       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:13.919291       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://10.0.2.15:8443/apis/policy/v1/poddisruptionbudgets?resourceVersion=30875": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:13.919399       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://10.0.2.15:8443/apis/policy/v1/poddisruptionbudgets?resourceVersion=30875": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:16.360771       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=30858": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:16.360957       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=30858": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:20.284733       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:20.285066       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://10.0.2.15:8443/apis/apps/v1/replicasets?resourceVersion=30876": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:24.408427       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: Get "https://10.0.2.15:8443/api/v1/replicationcontrollers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:24.408525       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://10.0.2.15:8443/api/v1/replicationcontrollers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:24.413586       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:24.413684       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/csidrivers?resourceVersion=30860": dial tcp 10.0.2.15:8443: connect: connection refused
W0131 08:43:25.096417       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: Get "https://10.0.2.15:8443/apis/policy/v1/poddisruptionbudgets?resourceVersion=30875": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:25.096512       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://10.0.2.15:8443/apis/policy/v1/poddisruptionbudgets?resourceVersion=30875": dial tcp 10.0.2.15:8443: connect: connection refused
E0131 08:43:39.101635       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: unknown (get persistentvolumes)
E0131 08:43:39.169102       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: unknown (get services)
W0131 08:43:39.181817       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
I0131 08:43:39.181914       1 trace.go:236] Trace[823496274]: "Reflector ListAndWatch" name:pkg/server/dynamiccertificates/configmap_cafile_content.go:206 (31-Jan-2024 08:43:28.250) (total time: 10931ms):
Trace[823496274]: ---"Objects listed" error:configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system" 10931ms (08:43:39.181)
Trace[823496274]: [10.931684867s] [10.931684867s] END
E0131 08:43:39.181958       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0131 08:43:39.387946       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: unknown (get nodes)
W0131 08:43:39.388738       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0131 08:43:39.388796       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0131 08:43:39.439730       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: unknown (get pods)
E0131 08:43:39.439908       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: unknown (get persistentvolumeclaims)

* 
* ==> kube-scheduler [9cd40e977caa] <==
* E0124 17:14:26.845346       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://10.0.2.15:8443/api/v1/nodes?resourceVersion=25396": net/http: TLS handshake timeout
E0124 17:14:26.844992       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://10.0.2.15:8443/api/v1/services?resourceVersion=25361": net/http: TLS handshake timeout
W0124 17:14:26.861903       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: Get "https://10.0.2.15:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&resourceVersion=25538": net/http: TLS handshake timeout
I0124 17:14:26.862185       1 trace.go:236] Trace[1693304918]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:16.858) (total time: 10003ms):
Trace[1693304918]: ---"Objects listed" error:Get "https://10.0.2.15:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&resourceVersion=25538": net/http: TLS handshake timeout 10003ms (17:14:26.861)
Trace[1693304918]: [10.003900266s] [10.003900266s] END
E0124 17:14:26.862258       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://10.0.2.15:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&resourceVersion=25538": net/http: TLS handshake timeout
I0124 17:14:34.492317       1 trace.go:236] Trace[1958304491]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:19.439) (total time: 15052ms):
Trace[1958304491]: ---"Objects listed" error:<nil> 15052ms (17:14:34.492)
Trace[1958304491]: [15.052264946s] [15.052264946s] END
W0124 17:14:36.588903       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=25367": net/http: TLS handshake timeout
I0124 17:14:36.589187       1 trace.go:236] Trace[204256829]: "Reflector ListAndWatch" name:pkg/server/dynamiccertificates/configmap_cafile_content.go:206 (24-Jan-2024 17:14:26.518) (total time: 10070ms):
Trace[204256829]: ---"Objects listed" error:Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=25367": net/http: TLS handshake timeout 10070ms (17:14:36.588)
Trace[204256829]: [10.070725462s] [10.070725462s] END
E0124 17:14:36.589260       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://10.0.2.15:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&resourceVersion=25367": net/http: TLS handshake timeout
I0124 17:14:39.887864       1 trace.go:236] Trace[1154416135]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:19.660) (total time: 20227ms):
Trace[1154416135]: ---"Objects listed" error:<nil> 20227ms (17:14:39.887)
Trace[1154416135]: [20.227561271s] [20.227561271s] END
I0124 17:14:39.905248       1 trace.go:236] Trace[1676458034]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:28.949) (total time: 10955ms):
Trace[1676458034]: ---"Objects listed" error:<nil> 10955ms (17:14:39.904)
Trace[1676458034]: [10.955846263s] [10.955846263s] END
I0124 17:14:40.276563       1 trace.go:236] Trace[902241087]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:19.590) (total time: 20686ms):
Trace[902241087]: ---"Objects listed" error:<nil> 20686ms (17:14:40.276)
Trace[902241087]: [20.686411421s] [20.686411421s] END
I0124 17:14:40.287966       1 trace.go:236] Trace[281002147]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:19.658) (total time: 20629ms):
Trace[281002147]: ---"Objects listed" error:<nil> 20629ms (17:14:40.287)
Trace[281002147]: [20.629145929s] [20.629145929s] END
I0124 17:14:40.404759       1 trace.go:236] Trace[1474028565]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:29.773) (total time: 10630ms):
Trace[1474028565]: ---"Objects listed" error:<nil> 10630ms (17:14:40.404)
Trace[1474028565]: [10.63094095s] [10.63094095s] END
I0124 17:14:40.407004       1 trace.go:236] Trace[1843481958]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:16.866) (total time: 23540ms):
Trace[1843481958]: ---"Objects listed" error:<nil> 23539ms (17:14:40.406)
Trace[1843481958]: [23.540007109s] [23.540007109s] END
I0124 17:14:40.407920       1 trace.go:236] Trace[729116759]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:19.440) (total time: 20967ms):
Trace[729116759]: ---"Objects listed" error:<nil> 20967ms (17:14:40.407)
Trace[729116759]: [20.967056007s] [20.967056007s] END
I0124 17:14:40.408367       1 trace.go:236] Trace[496042517]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:19.441) (total time: 20822ms):
Trace[496042517]: ---"Objects listed" error:<nil> 20822ms (17:14:40.263)
Trace[496042517]: [20.822174766s] [20.822174766s] END
I0124 17:14:40.409683       1 trace.go:236] Trace[656408536]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:16.578) (total time: 23830ms):
Trace[656408536]: ---"Objects listed" error:<nil> 23830ms (17:14:40.409)
Trace[656408536]: [23.830575094s] [23.830575094s] END
I0124 17:14:40.410396       1 trace.go:236] Trace[312315462]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:19.441) (total time: 20968ms):
Trace[312315462]: ---"Objects listed" error:<nil> 20968ms (17:14:40.410)
Trace[312315462]: [20.968723767s] [20.968723767s] END
I0124 17:14:40.837109       1 trace.go:236] Trace[2082581416]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:29.628) (total time: 11208ms):
Trace[2082581416]: ---"Objects listed" error:<nil> 11207ms (17:14:40.836)
Trace[2082581416]: [11.208058005s] [11.208058005s] END
I0124 17:14:40.839230       1 trace.go:236] Trace[1294190579]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:19.657) (total time: 21181ms):
Trace[1294190579]: ---"Objects listed" error:<nil> 21181ms (17:14:40.838)
Trace[1294190579]: [21.181971837s] [21.181971837s] END
I0124 17:14:41.303237       1 trace.go:236] Trace[1158882005]: "Reflector ListAndWatch" name:vendor/k8s.io/client-go/informers/factory.go:150 (24-Jan-2024 17:14:29.669) (total time: 11633ms):
Trace[1158882005]: ---"Objects listed" error:<nil> 11633ms (17:14:41.303)
Trace[1158882005]: [11.633235359s] [11.633235359s] END
E0124 17:17:22.672867       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: unknown (get storageclasses.storage.k8s.io) - error from a previous attempt: net/http: TLS handshake timeout
E0124 17:17:22.685135       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: unknown (get persistentvolumes) - error from a previous attempt: net/http: TLS handshake timeout
E0124 17:17:22.685578       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: unknown (get statefulsets.apps)
E0124 17:17:22.685781       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: unknown (get nodes) - error from a previous attempt: net/http: TLS handshake timeout
E0124 17:17:22.840014       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: unknown (get configmaps)
http2: server: error reading preface from client 127.0.0.1:58892: read tcp 127.0.0.1:10259->127.0.0.1:58892: read: connection reset by peer

* 
* ==> kubelet <==
* -- Journal begins at Wed 2024-01-31 07:55:44 UTC, ends at Wed 2024-01-31 08:46:15 UTC. --
Jan 31 08:44:13 minikube kubelet[1322]: E0131 08:44:13.019610    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-state-metrics\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=kube-state-metrics pod=prometheus-kube-state-metrics-745b475957-k9mgr_default(eb5b48b8-87a4-43fd-9b8a-a814701ebdf2)\"" pod="default/prometheus-kube-state-metrics-745b475957-k9mgr" podUID="eb5b48b8-87a4-43fd-9b8a-a814701ebdf2"
Jan 31 08:44:15 minikube kubelet[1322]: E0131 08:44:15.178573    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:44:15 minikube kubelet[1322]: E0131 08:44:15.182499    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:44:19 minikube kubelet[1322]: I0131 08:44:19.601422    1322 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="b2233aeb78509f5ed4fe79a52ad3a5ea0f63463fc17d5b6ca4a0b2146b46526b"
Jan 31 08:44:27 minikube kubelet[1322]: I0131 08:44:27.453582    1322 scope.go:117] "RemoveContainer" containerID="d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74"
Jan 31 08:44:27 minikube kubelet[1322]: E0131 08:44:27.455455    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-state-metrics\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=kube-state-metrics pod=prometheus-kube-state-metrics-745b475957-k9mgr_default(eb5b48b8-87a4-43fd-9b8a-a814701ebdf2)\"" pod="default/prometheus-kube-state-metrics-745b475957-k9mgr" podUID="eb5b48b8-87a4-43fd-9b8a-a814701ebdf2"
Jan 31 08:44:27 minikube kubelet[1322]: E0131 08:44:27.461153    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:44:29 minikube kubelet[1322]: E0131 08:44:29.113917    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:44:37 minikube kubelet[1322]: E0131 08:44:37.963989    1322 iptables.go:575] "Could not set up iptables canary" err=<
Jan 31 08:44:37 minikube kubelet[1322]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Jan 31 08:44:37 minikube kubelet[1322]:         Perhaps ip6tables or your kernel needs to be upgraded.
Jan 31 08:44:37 minikube kubelet[1322]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Jan 31 08:44:39 minikube kubelet[1322]: E0131 08:44:39.953889    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:44:40 minikube kubelet[1322]: E0131 08:44:40.514092    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:44:41 minikube kubelet[1322]: I0131 08:44:41.457880    1322 scope.go:117] "RemoveContainer" containerID="d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74"
Jan 31 08:44:41 minikube kubelet[1322]: E0131 08:44:41.458818    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-state-metrics\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=kube-state-metrics pod=prometheus-kube-state-metrics-745b475957-k9mgr_default(eb5b48b8-87a4-43fd-9b8a-a814701ebdf2)\"" pod="default/prometheus-kube-state-metrics-745b475957-k9mgr" podUID="eb5b48b8-87a4-43fd-9b8a-a814701ebdf2"
Jan 31 08:44:42 minikube kubelet[1322]: I0131 08:44:42.221979    1322 scope.go:117] "RemoveContainer" containerID="90dad179ab653b23ed4dd806f138eaa1cb14a2cb8f483002acda4ada587f7c07"
Jan 31 08:44:44 minikube kubelet[1322]: I0131 08:44:44.516629    1322 scope.go:117] "RemoveContainer" containerID="157aa2312b0f611db4b800168b66ec10d4dda12d94c1383115ed4ff66b4d237e"
Jan 31 08:44:44 minikube kubelet[1322]: I0131 08:44:44.615392    1322 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="90dad179ab653b23ed4dd806f138eaa1cb14a2cb8f483002acda4ada587f7c07"
Jan 31 08:44:46 minikube kubelet[1322]: I0131 08:44:46.967644    1322 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="157aa2312b0f611db4b800168b66ec10d4dda12d94c1383115ed4ff66b4d237e"
Jan 31 08:44:52 minikube kubelet[1322]: E0131 08:44:52.469476    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:44:54 minikube kubelet[1322]: I0131 08:44:54.453496    1322 scope.go:117] "RemoveContainer" containerID="d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74"
Jan 31 08:44:54 minikube kubelet[1322]: E0131 08:44:54.455432    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-state-metrics\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=kube-state-metrics pod=prometheus-kube-state-metrics-745b475957-k9mgr_default(eb5b48b8-87a4-43fd-9b8a-a814701ebdf2)\"" pod="default/prometheus-kube-state-metrics-745b475957-k9mgr" podUID="eb5b48b8-87a4-43fd-9b8a-a814701ebdf2"
Jan 31 08:44:54 minikube kubelet[1322]: E0131 08:44:54.511288    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:45:03 minikube kubelet[1322]: E0131 08:45:03.779081    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:45:06 minikube kubelet[1322]: E0131 08:45:06.500802    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:45:08 minikube kubelet[1322]: I0131 08:45:08.455031    1322 scope.go:117] "RemoveContainer" containerID="d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74"
Jan 31 08:45:08 minikube kubelet[1322]: E0131 08:45:08.456085    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-state-metrics\" with CrashLoopBackOff: \"back-off 1m20s restarting failed container=kube-state-metrics pod=prometheus-kube-state-metrics-745b475957-k9mgr_default(eb5b48b8-87a4-43fd-9b8a-a814701ebdf2)\"" pod="default/prometheus-kube-state-metrics-745b475957-k9mgr" podUID="eb5b48b8-87a4-43fd-9b8a-a814701ebdf2"
Jan 31 08:45:14 minikube kubelet[1322]: E0131 08:45:14.576741    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:45:18 minikube kubelet[1322]: E0131 08:45:18.462142    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:45:20 minikube kubelet[1322]: I0131 08:45:20.259433    1322 scope.go:117] "RemoveContainer" containerID="dd67eabddbfdd3b2acd20e66b2247686f71bee4703381c7e6e959cbb446cbfa3"
Jan 31 08:45:20 minikube kubelet[1322]: I0131 08:45:20.456913    1322 scope.go:117] "RemoveContainer" containerID="d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74"
Jan 31 08:45:29 minikube kubelet[1322]: E0131 08:45:29.563142    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:45:35 minikube kubelet[1322]: E0131 08:45:35.021424    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:45:36 minikube kubelet[1322]: E0131 08:45:36.874989    1322 iptables.go:575] "Could not set up iptables canary" err=<
Jan 31 08:45:36 minikube kubelet[1322]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Jan 31 08:45:36 minikube kubelet[1322]:         Perhaps ip6tables or your kernel needs to be upgraded.
Jan 31 08:45:36 minikube kubelet[1322]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Jan 31 08:45:40 minikube kubelet[1322]: E0131 08:45:40.463549    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:45:49 minikube kubelet[1322]: E0131 08:45:49.588830    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:45:51 minikube kubelet[1322]: E0131 08:45:51.462551    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:45:57 minikube kubelet[1322]: E0131 08:45:57.266184    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"metrics-server\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=metrics-server pod=metrics-server-7c66d45ddc-p79c5_kube-system(60a39492-59a4-49d2-acef-ba0e1641e1bf)\"" pod="kube-system/metrics-server-7c66d45ddc-p79c5" podUID="60a39492-59a4-49d2-acef-ba0e1641e1bf"
Jan 31 08:45:57 minikube kubelet[1322]: I0131 08:45:57.995040    1322 scope.go:117] "RemoveContainer" containerID="76dabeb962b99fbe0f7b917a066e0f05c564cd68ab03b63b680175ebe5a81db7"
Jan 31 08:45:57 minikube kubelet[1322]: I0131 08:45:57.995765    1322 scope.go:117] "RemoveContainer" containerID="d248809e053f9d9796b44547f6226228d6ae2c5c8cc4629648a7c497d90ff424"
Jan 31 08:45:57 minikube kubelet[1322]: E0131 08:45:57.996635    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"metrics-server\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=metrics-server pod=metrics-server-7c66d45ddc-p79c5_kube-system(60a39492-59a4-49d2-acef-ba0e1641e1bf)\"" pod="kube-system/metrics-server-7c66d45ddc-p79c5" podUID="60a39492-59a4-49d2-acef-ba0e1641e1bf"
Jan 31 08:46:00 minikube kubelet[1322]: E0131 08:46:00.728849    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-z9f8g" podUID="a8bd7447-867c-47ea-9207-e9d822180bb7"
Jan 31 08:46:01 minikube kubelet[1322]: I0131 08:46:01.324794    1322 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="76dabeb962b99fbe0f7b917a066e0f05c564cd68ab03b63b680175ebe5a81db7"
Jan 31 08:46:01 minikube kubelet[1322]: I0131 08:46:01.328076    1322 scope.go:117] "RemoveContainer" containerID="d248809e053f9d9796b44547f6226228d6ae2c5c8cc4629648a7c497d90ff424"
Jan 31 08:46:01 minikube kubelet[1322]: E0131 08:46:01.359168    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"metrics-server\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=metrics-server pod=metrics-server-7c66d45ddc-p79c5_kube-system(60a39492-59a4-49d2-acef-ba0e1641e1bf)\"" pod="kube-system/metrics-server-7c66d45ddc-p79c5" podUID="60a39492-59a4-49d2-acef-ba0e1641e1bf"
Jan 31 08:46:06 minikube kubelet[1322]: E0131 08:46:06.467069    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"books-app\" with ImagePullBackOff: \"Back-off pulling image \\\"books-management-sql\\\"\"" pod="default/books-app-deployment-5c866bfb66-n2g56" podUID="562eb7ee-e162-4bb5-b8e0-6df700769d61"
Jan 31 08:46:11 minikube kubelet[1322]: E0131 08:46:11.815412    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-state-metrics\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-state-metrics pod=prometheus-kube-state-metrics-745b475957-k9mgr_default(eb5b48b8-87a4-43fd-9b8a-a814701ebdf2)\"" pod="default/prometheus-kube-state-metrics-745b475957-k9mgr" podUID="eb5b48b8-87a4-43fd-9b8a-a814701ebdf2"
Jan 31 08:46:12 minikube kubelet[1322]: I0131 08:46:12.571357    1322 scope.go:117] "RemoveContainer" containerID="d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74"
Jan 31 08:46:12 minikube kubelet[1322]: I0131 08:46:12.573564    1322 scope.go:117] "RemoveContainer" containerID="86b068cb0ecf9e3a0f792dde72fe4dc7c5ec1800988ee6e44283a2b609d07716"
Jan 31 08:46:12 minikube kubelet[1322]: E0131 08:46:12.574784    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-state-metrics\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-state-metrics pod=prometheus-kube-state-metrics-745b475957-k9mgr_default(eb5b48b8-87a4-43fd-9b8a-a814701ebdf2)\"" pod="default/prometheus-kube-state-metrics-745b475957-k9mgr" podUID="eb5b48b8-87a4-43fd-9b8a-a814701ebdf2"
Jan 31 08:46:14 minikube kubelet[1322]: I0131 08:46:14.140475    1322 scope.go:117] "RemoveContainer" containerID="8e449a9f4d717198a341d156768694603e90038cc261cbcae3644d696ac4b208"
Jan 31 08:46:14 minikube kubelet[1322]: I0131 08:46:14.482182    1322 scope.go:117] "RemoveContainer" containerID="d248809e053f9d9796b44547f6226228d6ae2c5c8cc4629648a7c497d90ff424"
Jan 31 08:46:14 minikube kubelet[1322]: E0131 08:46:14.483098    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"metrics-server\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=metrics-server pod=metrics-server-7c66d45ddc-p79c5_kube-system(60a39492-59a4-49d2-acef-ba0e1641e1bf)\"" pod="kube-system/metrics-server-7c66d45ddc-p79c5" podUID="60a39492-59a4-49d2-acef-ba0e1641e1bf"
Jan 31 08:46:15 minikube kubelet[1322]: I0131 08:46:15.359840    1322 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="d04083f725766787791abc3a5517d6f00d8846b28f16b498565b80ffbe8fec74"
Jan 31 08:46:15 minikube kubelet[1322]: I0131 08:46:15.360605    1322 scope.go:117] "RemoveContainer" containerID="86b068cb0ecf9e3a0f792dde72fe4dc7c5ec1800988ee6e44283a2b609d07716"
Jan 31 08:46:15 minikube kubelet[1322]: E0131 08:46:15.361421    1322 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to \"StartContainer\" for \"kube-state-metrics\" with CrashLoopBackOff: \"back-off 2m40s restarting failed container=kube-state-metrics pod=prometheus-kube-state-metrics-745b475957-k9mgr_default(eb5b48b8-87a4-43fd-9b8a-a814701ebdf2)\"" pod="default/prometheus-kube-state-metrics-745b475957-k9mgr" podUID="eb5b48b8-87a4-43fd-9b8a-a814701ebdf2"

* 
* ==> kubernetes-dashboard [90dad179ab65] <==
* 
* ==> kubernetes-dashboard [a0247b02c893] <==
* 
* 
* ==> storage-provisioner [81ebde99ad3c] <==
* I0131 08:40:28.591575       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0131 08:40:28.697932       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: connect: connection refused

* 
* ==> storage-provisioner [faa4de385c52] <==
* I0131 08:44:38.933134       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0131 08:44:47.976831       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0131 08:44:47.976986       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0131 08:45:17.191723       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0131 08:45:17.784932       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"40d92f48-bd33-4ccd-9605-6b115a5b6e19", APIVersion:"v1", ResourceVersion:"31165", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_5ea90a65-f291-4473-81ec-45e360702036 became leader
I0131 08:45:17.840421       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_5ea90a65-f291-4473-81ec-45e360702036!
I0131 08:45:24.601428       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_5ea90a65-f291-4473-81ec-45e360702036!

